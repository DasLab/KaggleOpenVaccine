{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/tunguz/arnie')\n",
    "sys.path.append('/home/tunguz')\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_context('poster')\n",
    "sns.set_style('white')\n",
    "import numpy as np\n",
    "import re\n",
    "from arnie.pfunc import pfunc\n",
    "from arnie.free_energy import free_energy\n",
    "from arnie.bpps import bpps\n",
    "from arnie.mfe import mfe\n",
    "import arnie.utils as utils\n",
    "from decimal import Decimal\n",
    "import ipynb\n",
    "import json\n",
    "import pickle\n",
    "import csv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split,KFold, GroupKFold,StratifiedKFold\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "import pandas as pd\n",
    "\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_structure_to_bps(secstruct):\n",
    "\n",
    "    bps = []\n",
    "\n",
    "    left_delimiters = ['(','{','[']\n",
    "    right_delimiters = [')','}',']']\n",
    "\n",
    "    for (left_delim, right_delim) in list(zip(left_delimiters, right_delimiters)):\n",
    "\n",
    "        left_list = []\n",
    "        for i, char in enumerate(secstruct):\n",
    "            if char == left_delim:\n",
    "                left_list.append(i)\n",
    "\n",
    "            elif char == right_delim:\n",
    "                bps.append([left_list[-1],i])\n",
    "                left_list = left_list[:-1]\n",
    "\n",
    "        assert len(left_list)==0\n",
    "\n",
    "    return bps\n",
    "\n",
    "def secstruct_to_partner(secstruct):\n",
    "    '''Convert secondary structure string to partner array.\n",
    "    I.E. ((.)) -> [4,3,-1,1,0]\n",
    "    '''\n",
    "    bps = convert_structure_to_bps(secstruct)\n",
    "    partner_vec = -1*np.ones([len(secstruct)]) \n",
    "\n",
    "    for (i,j) in bps:\n",
    "        partner_vec[i] = j\n",
    "        partner_vec[j] = i\n",
    "\n",
    "    return partner_vec\n",
    "\n",
    "def write_bprna_string(dbn_string):\n",
    "    '''Input: dot-parenthesis string\n",
    "    Output: bpRNA-style loop type assignments'''\n",
    "    \n",
    "    pair_partners = secstruct_to_partner(dbn_string)\n",
    "    \n",
    "    #print(pair_partners)\n",
    "    bprna_string=['u']*len(dbn_string)\n",
    "\n",
    "    # assign stems\n",
    "    for s_ind, s in enumerate(dbn_string):\n",
    "        if s != '.':\n",
    "            bprna_string[s_ind] = 'S'\n",
    "                \n",
    "    # get loop regions\n",
    "    \n",
    "    while 'u' in ''.join(bprna_string):\n",
    "        #print(''.join(bprna_string))\n",
    "\n",
    "        obj = re.search(r\"uu*\", ''.join(bprna_string))\n",
    "        start_ind, end_ind = obj.start(), obj.end()\n",
    "        \n",
    "        n_open_hps = dbn_string[:start_ind].count(')') - dbn_string[:start_ind].count('(')\n",
    "        \n",
    "        if n_open_hps == 0:\n",
    "            bprna_string[start_ind:end_ind] = 'E'*(end_ind-start_ind)\n",
    "\n",
    "        else:\n",
    "\n",
    "            last_stem_pairing = int(pair_partners[start_ind - 1])\n",
    "            next_stem_pairing = int(pair_partners[end_ind ])\n",
    "            \n",
    "            if last_stem_pairing == end_ind:\n",
    "                bprna_string[start_ind:end_ind] = 'H'*(end_ind-start_ind)\n",
    "\n",
    "            elif (last_stem_pairing - 1 == next_stem_pairing):\n",
    "                bprna_string[start_ind:end_ind] = 'B'*(end_ind-start_ind)\n",
    "                \n",
    "            elif dbn_string[start_ind-1]==')' and dbn_string[end_ind]=='(':\n",
    "                bprna_string[start_ind:end_ind] = 'M'*(end_ind-start_ind)\n",
    "                \n",
    "            else:\n",
    "                if dbn_string[next_stem_pairing+1:last_stem_pairing] == '.'*(last_stem_pairing - next_stem_pairing-1):\n",
    "                    bprna_string[start_ind:end_ind] = 'I'*(end_ind-start_ind)\n",
    "                    bprna_string[next_stem_pairing+1:last_stem_pairing] = 'I'*(last_stem_pairing - next_stem_pairing-1)\n",
    "\n",
    "                else:\n",
    "                    bprna_string[start_ind:end_ind] = 'M'*(end_ind - start_ind)\n",
    "    return ''.join(bprna_string)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_input(sequence, bprna_string, window_size=1, pad=0):\n",
    "    '''Creat input/output for regression model for predicting structure probing data.\n",
    "    Inputs:\n",
    "    \n",
    "    dataframe (in EternaBench RDAT format)\n",
    "    window_size: size of window (in one direction). so window_size=1 is a total window size of 3\n",
    "    pad: number of nucleotides at start to not include\n",
    "    seq (bool): include sequence encoding\n",
    "    struct (bool): include bpRNA structure encoding\n",
    "    \n",
    "    Outputs:\n",
    "    Input array (n_samples x n_features): array of windowed input features\n",
    "    feature_names (list, length = kernel x window): feature names, i.e. `S_-12`\n",
    "    \n",
    "    '''    \n",
    "    inpts = []\n",
    "\n",
    "    feature_kernel=['A','U','G','C','H','E','I','M','B','S', 'X']\n",
    "\n",
    "    length = len(sequence)\n",
    "    arr = np.zeros([length,len(feature_kernel)])\n",
    "        \n",
    "    for index in range(length):\n",
    "        ctr=0\n",
    "        for char in ['A','U','G','C']:\n",
    "            if sequence[index]==char:\n",
    "                arr[index,ctr]+=1\n",
    "            ctr+=1\n",
    "\n",
    "        for char in ['H','E','I','M','B','S', 'X']:\n",
    "            if bprna_string[index]==char:\n",
    "                arr[index,ctr]+=1\n",
    "            ctr+=1\n",
    "\n",
    "        # add zero padding to the side\n",
    "\n",
    "    padded_arr = np.vstack([np.zeros([window_size,len(feature_kernel)]), arr, np.zeros([window_size,len(feature_kernel)])])\n",
    "\n",
    "    for index in range(length):\n",
    "        new_index = index+window_size-pad\n",
    "        tmp = padded_arr[new_index-window_size:new_index+window_size+1]\n",
    "        inpts.append(tmp.flatten())\n",
    "            \n",
    "    return np.array(inpts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS_WGTS = [0.3, 0.3, 0.3, 0.05, 0.05] #column weights, need to sum up to 1\n",
    "\n",
    "\n",
    "DIST_NEW = True\n",
    "DIST_NEW2 = True\n",
    "\n",
    "BBP = True\n",
    "BBP1 = True\n",
    "BBP2 = True\n",
    "BBP3 = True\n",
    "BBP4 = True\n",
    "\n",
    "BBP_TOTAL = BBP+BBP1+BBP2+BBP3+BBP4*4\n",
    "\n",
    "# This will tell us the columns we are predicting\n",
    "pred_cols = ['reactivity', 'deg_Mg_pH10', 'deg_Mg_50C', 'deg_pH10', 'deg_50C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = \"AUGUUCGUCUUCCUCGUCUUGCUGCCCCUGGUCAGCUCUCAGUGUGUGAACCUUACGACUCGCACGCAGCUGCCCCCUGCAUAUACUAACUCUUUCACGCGAGGGGUGUACUAUCCGGACAAGGUAUUCAGAAGCUCCGUGCUGCAUAGCACACAGGAUCUGUUCUUGCCGUUCUUCAGUAAUGUAACAUGGUUUCACGCCAUUCAUGUCUCAGGCACGAAUGGAACUAAAAGGUUCGAUAACCCAGUGCUCCCGUUCAAUGAUGGGGUGUACUUCGCGAGUACAGAGAAAAGCAACAUAAUCCGGGGCUGGAUUUUCGGGACGACGUUGGAUUCUAAGACCCAAAGCCUUCUUAUCGUUAACAACGCGACGAACGUCGUCAUAAAGGUGUGCGAAUUUCAGUUUUGUAACGAUCCGUUUCUCGGUGUGUACUACCAUAAGAAUAACAAGUCUUGGAUGGAAUCAGAAUUUAGGGUCUACAGUUCAGCAAAUAACUGUACUUUUGAGUAUGUAAGCCAGCCUUUCCUCAUGGAUCUCGAGGGAAAACAGGGCAAUUUCAAAAACUUGCGAGAGUUUGUGUUUAAAAAUAUCGACGGGUACUUCAAGAUCUAUUCCAAGCAUACUCCAAUCAAUCUGGUAAGGGAUCUGCCCCAGGGUUUCUCCGCACUCGAACCUCUUGUGGACUUGCCUAUCGGUAUCAAUAUCACACGGUUUCAAACACUUCUUGCUCUCCACAGAAGCUAUCUGACUCCAGGUGAUUCAUCCUCCGGGUGGACAGCUGGAGCCGCCGCUUAUUAUGUAGGUUACCUCCAACCACGAACUUUCCUCCUCAAGUACAACGAAAACGGCACGAUAACAGACGCUGUUGAUUGUGCGCUGGACCCCUUGAGUGAAACAAAAUGCACCCUUAAAAGUUUUACCGUGGAAAAAGGCAUAUACCAGACUAGCAAUUUCCGCGUUCAGCCAACCGAGAGUAUAGUUCGCUUCCCUAACAUUACUAAUCUUUGUCCUUUUGGCGAAGUCUUCAAUGCGACUCGAUUCGCGUCUGUAUAUGCAUGGAAUAGGAAACGAAUUAGUAACUGCGUCGCAGACUACUCAGUGUUGUACAAUAGUGCUUCCUUUUCCACCUUUAAGUGUUAUGGAGUUAGCCCAACUAAACUGAAUGACCUCUGUUUUACUAACGUCUAUGCAGAUUCCUUCGUAAUACGGGGGGACGAGGUCCGGCAAAUCGCGCCUGGGCAAACUGGGAAGAUCGCAGAUUACAACUACAAACUGCCCGAUGACUUCACAGGAUGCGUGAUUGCCUGGAACUCUAACAACUUGGAUUCCAAGGUCGGAGGCAAUUACAAUUAUUUGUAUCGAUUGUUUAGGAAAUCUAAUUUGAAGCCCUUCGAACGCGACAUCAGUACGGAGAUAUAUCAGGCCGGUAGCACCCCUUGUAAUGGCGUUGAAGGGUUUAACUGCUAUUUCCCUUUGCAAUCUUAUGGAUUUCAACCUACGAACGGUGUAGGGUACCAACCGUAUCGCGUAGUUGUGCUGAGUUUCGAGCUCUUGCAUGCCCCUGCCACAGUCUGUGGUCCGAAGAAAUCAACAAACCUUGUUAAAAAUAAGUGCGUGAAUUUUAAUUUCAACGGUCUGACAGGCACAGGAGUACUGACCGAGUCCAAUAAAAAGUUCCUCCCGUUUCAACAGUUUGGAAGGGAUAUCGCCGACACAACAGAUGCCGUACGCGACCCUCAGACUUUGGAAAUCCUUGACAUAACUCCUUGUUCCUUUGGCGGGGUAAGCGUUAUUACUCCAGGUACGAAUACCAGCAAUCAAGUCGCCGUCCUCUACCAAGAUGUAAACUGCACUGAGGUCCCUGUUGCUAUUCAUGCCGACCAACUGACCCCUACCUGGCGAGUUUAUUCAACAGGCUCCAAUGUUUUUCAAACACGAGCCGGAUGUUUGAUAGGUGCCGAGCACGUGAACAACUCCUAUGAGUGUGACAUACCCAUCGGUGCCGGCAUCUGCGCAUCUUAUCAAACUCAGACAAACAGCCCCCGAAGAGCUAGGUCCGUAGCUUCACAGUCCAUCAUCGCCUAUACGAUGUCAUUGGGAGCGGAGAACUCUGUGGCUUACUCCAAUAACAGCAUCGCUAUUCCGACAAAUUUUACUAUAAGCGUCACAACGGAAAUCUUGCCUGUAAGUAUGACAAAAACUAGCGUGGAUUGUACAAUGUACAUUUGUGGCGACUCCACGGAAUGCUCUAACUUGCUGCUUCAGUAUGGGUCCUUUUGUACGCAACUCAAUAGGGCACUGACGGGAAUAGCAGUGGAGCAAGAUAAGAAUACCCAAGAAGUCUUUGCCCAGGUUAAACAGAUAUACAAAACACCUCCGAUUAAGGACUUCGGCGGCUUUAACUUCUCUCAAAUACUUCCCGACCCCAGUAAACCAUCAAAGCGGAGCUUUAUCGAGGAUCUGCUGUUCAAUAAGGUCACACUGGCUGAUGCCGGGUUCAUCAAACAGUACGGGGACUGUCUCGGCGAUAUUGCAGCACGCGAUCUUAUCUGCGCCCAGAAGUUCAAUGGGUUGACAGUUCUCCCCCCGCUCUUGACAGAUGAAAUGAUCGCACAGUAUACCAGCGCCCUCCUGGCCGGGACAAUUACCUCCGGAUGGACUUUUGGGGCAGGUGCAGCCCUUCAGAUUCCCUUUGCAAUGCAGAUGGCCUAUCGGUUCAACGGUAUUGGCGUUACUCAAAAUGUGCUUUACGAAAACCAAAAACUGAUAGCGAACCAAUUCAAUAGUGCAAUCGGGAAGAUACAAGACUCUCUCUCAUCCACUGCAUCCGCUCUGGGAAAGCUCCAAGACGUCGUCAAUCAGAAUGCCCAGGCUCUCAACACCUUGGUGAAACAGCUUUCCUCAAACUUUGGAGCGAUAAGUAGCGUGCUUAACGAUAUCCUUUCACGACUCGACCCACCCGAGGCCGAAGUGCAGAUAGACAGACUUAUUACUGGCAGGCUGCAGUCCCUUCAGACUUAUGUUACGCAACAGCUUAUUAGGGCAGCUGAAAUAAGAGCAUCAGCCAAUUUGGCGGCUACGAAAAUGUCCGAGUGCGUCCUCGGCCAGUCUAAGAGGGUAGAUUUCUGCGGGAAGGGCUAUCAUUUGAUGAGCUUUCCUCAGUCAGCGCCACAUGGCGUUGUUUUCCUGCAUGUGACCUACGUGCCUGCCCAGGAAAAGAACUUUACCACGGCCCCUGCAAUAUGCCAUGAUGGCAAAGCACAUUUUCCCCGCGAAGGUGUUUUCGUAUCUAAUGGAACCCAUUGGUUCGUCACUCAGCGGAACUUUUACGAGCCACAGAUUAUAACCACCGACAACACUUUCGUUUCCGGCAACUGCGAUGUUGUAAUAGGGAUCGUUAACAAUACAGUGUACGACCCGCUUCAGCCCGAGCUGGACUCAUUCAAAGAGGAACUCGACAAAUAUUUCAAGAACCAUACAUCUCCGGACGUAGAUCUUGGUGAUAUAUCCGGCAUAAAUGCAUCAGUGGUUAAUAUCCAGAAGGAAAUAGAUAGACUCAACGAAGUUGCAAAGAAUCUCAAUGAGAGCCUGAUCGAUCUCCAGGAACUCGGAAAAUACGAACAAUACAUUAAAUGGCCCUGGUACAUAUGGUUGGGGUUCAUUGCCGGACUGAUCGCCAUCGUUAUGGUUACCAUUAUGUUGUGUUGCAUGACAAGUUGCUGCUCAUGUCUUAAGGGUUGUUGUAGUUGCGGCUCUUGCUGCAAAUUCGAUGAGGACGAUAGUGAGCCUGUUUUGAAGGGCGUCAAAUUGCAUUAUACUUAA\"\n",
    "mfe_structure = mfe(sequence, package='eternafold')\n",
    "bprna_string = write_bprna_string(mfe_structure)\n",
    "bp_matrix = bpps(sequence, package='eternafold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>bpRNA_string</th>\n",
       "      <th>structure</th>\n",
       "      <th>seq_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AUGUUCGUCUUCCUCGUCUUGCUGCCCCUGGUCAGCUCUCAGUGUG...</td>\n",
       "      <td>EEEESSSSSSSSISSSMMMMMMMMMSSSMMSBSSSSSBBBBSSSSS...</td>\n",
       "      <td>....((((((((.(((.........(((..(.(((((....(((((...</td>\n",
       "      <td>3822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           sequence  \\\n",
       "0   0  AUGUUCGUCUUCCUCGUCUUGCUGCCCCUGGUCAGCUCUCAGUGUG...   \n",
       "\n",
       "                                        bpRNA_string  \\\n",
       "0  EEEESSSSSSSSISSSMMMMMMMMMSSSMMSBSSSSSBBBBSSSSS...   \n",
       "\n",
       "                                           structure  seq_length  \n",
       "0  ....((((((((.(((.........(((..(.(((((....(((((...        3822  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data = [{'id': 0, 'sequence': sequence, 'bpRNA_string': bprna_string, 'structure': mfe_structure, 'seq_length': len(sequence)}])\n",
    "df.sort_values(by='seq_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_list_to_array(df):\n",
    "    \"\"\"\n",
    "    Input: dataframe of shape (x, y), containing list of length l\n",
    "    Return: np.array of shape (x, l, y)\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.transpose(\n",
    "        np.array(df.values.tolist()),\n",
    "        (0, 2, 1)\n",
    "    )\n",
    "\n",
    "\n",
    "def calc_neighbor(d, dim, n):\n",
    "    lst_x,lst_y = np.where(d==n)\n",
    "    for c, x in enumerate(lst_x):\n",
    "        y = lst_y[c]    \n",
    "        if x+1<dim:\n",
    "            d[x+1,y] = min(d[x+1,y], n+1)\n",
    "        if y+1<dim:\n",
    "            d[x,y+1] = min(d[x,y+1], n+1)\n",
    "        if x-1>=0:\n",
    "            d[x-1,y] = min(d[x-1,y], n+1)\n",
    "        if y-1>=0:\n",
    "            d[x,y-1] = min(d[x,y-1], n+1)\n",
    "    return d\n",
    "            \n",
    "\n",
    "def get_distance_matrix_2d(Ss):\n",
    "    Ds = []\n",
    "    n = Ss.shape[0]\n",
    "    dim = Ss.shape[1]\n",
    "    for i in range(n):\n",
    "        s = Ss[i,:,:,0]\n",
    "        d = 10+np.zeros_like(s)\n",
    "        d[s==1] = 1\n",
    "        for i in range(dim):\n",
    "            d[i,i] = 0\n",
    "        for x in range(0, 9):\n",
    "            d = calc_neighbor(d, dim, x)\n",
    "        Ds.append(d)\n",
    "    Ds =  np.array(Ds) + 1\n",
    "    Ds = 1/Ds\n",
    "    Ds = Ds[:, :,:, None]\n",
    "    \n",
    "    Dss = []\n",
    "    for i in [1, 2, 4]:\n",
    "        Dss.append(Ds ** i)\n",
    "    Ds = np.stack(Dss, axis = 3)\n",
    "    return Ds[:,:,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss functions\n",
    "def MCRMSE(y_true, y_pred):\n",
    "    colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=(1))\n",
    "    return tf.reduce_mean(tf.sqrt(colwise_mse), axis=1)\n",
    "\n",
    "\n",
    "from tensorflow.keras import losses\n",
    "\n",
    "class MSE(losses.MeanSquaredError):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        losses.MeanSquaredError.__init__(self, *args, **kwargs)\n",
    "\n",
    "    def __call__(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.where(tf.math.is_nan(y_true), y_pred, y_true)\n",
    "        \n",
    "        temp = losses.MeanSquaredError.__call__(self, y_true[:, :, 0], y_pred[:, :, 0], sample_weight=None)\n",
    "        temp = tf.sqrt(temp+1e-12)\n",
    "        temp = tf.tensordot(temp,sample_weight,1)/tf.reduce_sum(sample_weight)\n",
    "        s = temp*LOSS_WGTS[0]\n",
    "#         s = tf.sqrt(temp)*LOSS_WGTS[0]\n",
    "        for i in range(1,5):\n",
    "            temp = losses.MeanSquaredError.__call__(self, y_true[:, :, i], y_pred[:, :, i], sample_weight=None)\n",
    "            temp = tf.sqrt(temp+1e-12)\n",
    "            temp = tf.tensordot(temp,sample_weight,1)/tf.reduce_sum(sample_weight)\n",
    "#             s += tf.sqrt(temp)*LOSS_WGTS[i]\n",
    "            s += (temp)*LOSS_WGTS[i]\n",
    "            \n",
    "        return s\n",
    "    \n",
    "    \n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def mean_squared_error1(y_true, y_pred, sample_weight):\n",
    "    return np.sum((np.sqrt(np.mean((y_true-y_pred)**2, axis=1)))*sample_weight)/np.sum(sample_weight)\n",
    "\n",
    "def MCRMSE_NAN_sample_wgt(y_true, y_pred, sample_weight=None, loss_cap=None):\n",
    "    if loss_cap is not None:\n",
    "        y_true_adj = np.minimum(np.maximum(y_true, y_pred-loss_cap), y_pred+loss_cap)\n",
    "        return MCRMSE_NAN_sample_wgt(y_true_adj, y_pred, sample_weight=sample_weight, loss_cap=None)\n",
    "    \n",
    "    y_wgt = tf.ones_like(y_true)\n",
    "    y_true = tf.where(tf.math.is_nan(y_true), y_pred, y_true)\n",
    "\n",
    "    s = (mean_squared_error1(y_true[:, :, 0], y_pred[:, :, 0], sample_weight=sample_weight)/(tf.reduce_mean(y_wgt[:,:, 0])))*LOSS_WGTS[0]\n",
    "    for i in range(1,5):\n",
    "        s += (mean_squared_error1(y_true[:, :, i], y_pred[:, :, i], sample_weight=sample_weight)/(tf.reduce_mean(y_wgt[:,:, i])))*LOSS_WGTS[i]\n",
    "    return s\n",
    "\n",
    "def MCRMSE_NAN_sample_wgt_single(y_true, y_pred, sample_weight=None, loss_cap=None):\n",
    "    if loss_cap is not None:\n",
    "        y_true_adj = np.minimum(np.maximum(y_true, y_pred-loss_cap), y_pred+loss_cap)\n",
    "        return MCRMSE_NAN_sample_wgt_single(y_true_adj, y_pred, sample_weight=sample_weight, loss_cap=None)\n",
    "        \n",
    "    y_wgt = tf.ones_like(y_true)\n",
    "    y_true = tf.where(tf.math.is_nan(y_true), y_pred, y_true)\n",
    "\n",
    "    s = (mean_squared_error1(y_true[:, :], y_pred[:, :], sample_weight=sample_weight)/(tf.reduce_mean(y_wgt[:,:])))\n",
    "    return s\n",
    "\n",
    "\n",
    "def MCRMSE_NAN(y_true, y_pred, wgt=LOSS_WGTS, loss_cap=None):\n",
    "    return MCRMSE_NAN_sample_wgt(y_true, y_pred, sample_weight=tf.ones_like(y_true[:,0,0]), loss_cap=loss_cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse inputs\n",
    "def reverse_input(train_input):\n",
    "    reverse = train_input[:, ::-1, :]\n",
    "    return reverse\n",
    "\n",
    "def reverse_BBP_3D(mat):\n",
    "    return mat[:, ::-1, ::-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://www.kaggle.com/xhlulu/openvaccine-simple-gru-model\n",
    "\n",
    "def gru_layer(hidden_dim, dropout):\n",
    "    return L.Bidirectional(\n",
    "        L.GRU(hidden_dim, dropout=dropout, return_sequences=True, kernel_initializer='orthogonal')\n",
    "    )\n",
    "\n",
    "\n",
    "def lstm_layer(hidden_dim, dropout):\n",
    "    return L.Bidirectional(\n",
    "              L.LSTM(hidden_dim,dropout=dropout, return_sequences=True,kernel_initializer = 'orthogonal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://www.kaggle.com/ragnar123/wavenet-gru-baseline\n",
    "\n",
    "def wave_block(x, filters, kernel_size, n):\n",
    "    dilation_rates = [2 ** i for i in range(n)]\n",
    "    x = tf.keras.layers.Conv1D(filters = filters, \n",
    "                               kernel_size = 1,\n",
    "                               padding = 'same')(x)\n",
    "    res_x = x\n",
    "    for dilation_rate in dilation_rates:\n",
    "        tanh_out = tf.keras.layers.Conv1D(filters = filters,\n",
    "                          kernel_size = kernel_size,\n",
    "                          padding = 'same', \n",
    "                          activation = 'tanh', \n",
    "                          dilation_rate = dilation_rate)(x)\n",
    "        sigm_out = tf.keras.layers.Conv1D(filters = filters,\n",
    "                          kernel_size = kernel_size,\n",
    "                          padding = 'same',\n",
    "                          activation = 'sigmoid', \n",
    "                          dilation_rate = dilation_rate)(x)\n",
    "        x = tf.keras.layers.Multiply()([tanh_out, sigm_out])\n",
    "        x = tf.keras.layers.Conv1D(filters = filters,\n",
    "                   kernel_size = 1,\n",
    "                   padding = 'same')(x)\n",
    "        res_x = tf.keras.layers.Add()([res_x, x])\n",
    "    return res_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main model edited from https://www.kaggle.com/mrkmakr/covid-ae-pretrain-gnn-attn-cnn\n",
    "\n",
    "def attention(x_inner, x_outer, n_factor, dropout):\n",
    "    x_Q =  L.Conv1D(n_factor, 1, activation='linear', \n",
    "                  kernel_initializer='glorot_uniform',\n",
    "                  bias_initializer='glorot_uniform',\n",
    "                 )(x_inner)\n",
    "    x_K =  L.Conv1D(n_factor, 1, activation='linear', \n",
    "                  kernel_initializer='glorot_uniform',\n",
    "                  bias_initializer='glorot_uniform',\n",
    "                 )(x_outer)\n",
    "    x_V =  L.Conv1D(n_factor, 1, activation='linear', \n",
    "                  kernel_initializer='glorot_uniform',\n",
    "                  bias_initializer='glorot_uniform',\n",
    "                 )(x_outer)\n",
    "    x_KT = L.Permute((2, 1))(x_K)\n",
    "    res = L.Lambda(lambda c: K.batch_dot(c[0], c[1]) / np.sqrt(n_factor))([x_Q, x_KT])\n",
    "    att = L.Lambda(lambda c: K.softmax(c, axis=-1))(res)\n",
    "    att = L.Lambda(lambda c: K.batch_dot(c[0], c[1]))([att, x_V])\n",
    "    return att\n",
    "\n",
    "def multi_head_attention(x, y, n_factor, n_head, dropout):\n",
    "    if n_head == 1:\n",
    "        att = attention(x, y, n_factor, dropout)\n",
    "    else:\n",
    "        n_factor_head = n_factor // n_head\n",
    "        heads = [attention(x, y, n_factor_head, dropout) for i in range(n_head)]\n",
    "        att = L.Concatenate()(heads)\n",
    "        att = L.Dense(n_factor, \n",
    "                      kernel_initializer='glorot_uniform',\n",
    "                      bias_initializer='glorot_uniform',\n",
    "                     )(att)\n",
    "    x = L.Add()([x, att])\n",
    "    x = L.LayerNormalization()(x)\n",
    "    if dropout > 0:\n",
    "        x = L.Dropout(dropout)(x)\n",
    "    return x\n",
    "\n",
    "def res(x, unit, kernel = 3, rate = 0.1):\n",
    "    h = L.Conv1D(unit, kernel, 1, padding = \"same\", activation = None)(x)\n",
    "    h = L.LayerNormalization()(h)\n",
    "    h = L.LeakyReLU()(h)\n",
    "    h = L.Dropout(rate)(h)\n",
    "    return L.Add()([x, h])\n",
    "\n",
    "def forward(x, unit, kernel = 3, rate = 0.1):\n",
    "    h = L.Conv1D(unit, kernel, 1, padding = \"same\", activation = None)(x)\n",
    "    h = L.LayerNormalization()(h)\n",
    "    h = L.Dropout(rate)(h)\n",
    "    h = L.LeakyReLU()(h)\n",
    "    h = res(h, unit, kernel, rate)\n",
    "    return h\n",
    "\n",
    "def adj_attn(x, adj, unit, n = 2, rate = 0.1):\n",
    "    x_a = x\n",
    "    x_as = []\n",
    "    for i in range(n):\n",
    "        x_a = forward(x_a, unit)\n",
    "        x_a = tf.matmul(adj, x_a)\n",
    "        x_as.append(x_a)\n",
    "    if n == 1:\n",
    "        x_a = x_as[0]\n",
    "    else:\n",
    "        x_a = L.Concatenate()(x_as)\n",
    "    x_a = forward(x_a, unit)\n",
    "    return x_a\n",
    "\n",
    "\n",
    "def get_base(config, dim=None):\n",
    "    node = tf.keras.Input(shape = (dim, X_node.shape[2]), name = \"node\")\n",
    "    adj = tf.keras.Input(shape = (dim, dim, As.shape[3]), name = \"adj\")\n",
    "    \n",
    "    adj_learned = L.Dense(1, \"relu\")(adj)\n",
    "    adj_all = L.Concatenate(axis = 3)([adj, adj_learned])\n",
    "        \n",
    "    xs = []\n",
    "    xs.append(node)\n",
    "    x1 = forward(node, 128*2, kernel = 3, rate = 0.1)\n",
    "    x2 = forward(x1, 64*2, kernel = 6, rate = 0.1)\n",
    "    x3 = forward(x2, 32*2, kernel = 15, rate = 0.1)\n",
    "    x4 = forward(x3, 16*2, kernel = 30, rate = 0.1)\n",
    "    x = L.Concatenate()([x1, x2, x3, x4])\n",
    "    \n",
    "    for unit in [64*2, 32*2]:\n",
    "        x_as = []\n",
    "        for i in range(adj_all.shape[3]):\n",
    "            x_a = adj_attn(x, adj_all[:, :, :, i], unit, rate = 0)\n",
    "            x_as.append(x_a)\n",
    "        x_c = forward(x, unit, kernel = 30)\n",
    "        \n",
    "        x = L.Concatenate()(x_as + [x_c])\n",
    "        x = forward(x, unit)\n",
    "        x = multi_head_attention(x, x, unit, 4, 0.0)\n",
    "        xs.append(x)\n",
    "        \n",
    "    x = L.Concatenate()(xs)\n",
    "\n",
    "    model = tf.keras.Model(inputs = [node, adj], outputs = [x])\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_ae_model(base, config, dim=None):\n",
    "    node = tf.keras.Input(shape = (dim, X_node.shape[2]), name = \"node\")\n",
    "    adj = tf.keras.Input(shape = (dim, dim, As.shape[3]), name = \"adj\")\n",
    "\n",
    "    x = base([L.SpatialDropout1D(0.3)(node), adj])\n",
    "    x = forward(x, 64*2, rate = 0.2)\n",
    "    p = L.Dense(X_node.shape[2], \"sigmoid\")(x)\n",
    "    \n",
    "\n",
    "    node_1 = tf.where((node>1-1e-8), node, tf.zeros_like(node))\n",
    "    node_0 = tf.where((node<1e-8), node, tf.ones_like(node))\n",
    "    node_float = tf.where((node<=1-1e-8)&(node>=1e-8), node, p) \n",
    "    \n",
    "    loss = - tf.reduce_mean(20 * node_1 * tf.math.log(p + 1e-4) + (1 - node_0) * tf.math.log(1 - p + 1e-4) - 5*(node_float-p)**2)\n",
    "    \n",
    "    model = tf.keras.Model(inputs = [node, adj], outputs = [loss])\n",
    "    \n",
    "    opt = get_optimizer()\n",
    "    model.compile(optimizer = opt, loss = lambda t, y : y)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_model(base, config, dim=None):\n",
    "    node = tf.keras.Input(shape = (dim, X_node.shape[2]), name = \"node\")\n",
    "    adj = tf.keras.Input(shape = (dim, dim, As.shape[3]), name = \"adj\")\n",
    "    \n",
    "    x = base([node, adj])\n",
    "    if not Diversity_type in ['forward']:\n",
    "        x = forward(x, 128*2, rate = 0.2)\n",
    "    \n",
    "    if Diversity_type == 'gru':\n",
    "        x = gru_layer(128*2, dropout=0.2)(x)\n",
    "    elif Diversity_type == 'lstm':\n",
    "        x = lstm_layer(128*2, dropout=0.2)(x)\n",
    "    elif Diversity_type == 'forward':\n",
    "        x = forward(x, 128*4, kernel=5, rate = 0.1)\n",
    "        x = forward(x, 128*4, kernel=3, rate = 0.1)\n",
    "        x = forward(x, 128*4, kernel=1, rate = 0.1)\n",
    "    elif Diversity_type == 'wave':\n",
    "        dropout = 0.1\n",
    "        x = wave_block(x, 16*2, 3, 12)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Dropout(dropout)(x)\n",
    "\n",
    "        x = wave_block(x, 32*2, 3, 8)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Dropout(dropout)(x)\n",
    "\n",
    "        x = wave_block(x, 64*2, 3, 4)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Dropout(dropout)(x)\n",
    "\n",
    "        x = wave_block(x, 128*2, 3, 1)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Dropout(dropout)(x)\n",
    "    \n",
    "    \n",
    "    x = x[:, 1:-1,:]\n",
    "    x = L.Dense(5)(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs = [node, adj], outputs = [x])\n",
    "    \n",
    "    opt = get_optimizer()\n",
    "    model.compile(optimizer = opt, loss = MSE(reduction=tf.keras.losses.Reduction.NONE))#mcrmse_loss)\n",
    "    return model\n",
    "\n",
    "def get_optimizer():\n",
    "#     sgd = tf.keras.optimizers.SGD(0.05, momentum = 0.9, nesterov=True)\n",
    "    adam = tf.optimizers.Adam()\n",
    "#     radam = tfa.optimizers.RectifiedAdam()\n",
    "#     lookahead = tfa.optimizers.Lookahead(adam, sync_period=6)\n",
    "#     swa = tfa.optimizers.SWA(adam)\n",
    "    return adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sequence\n",
    "def return_ohe(n, i):\n",
    "    tmp = [0] * n\n",
    "    tmp[i] = 1\n",
    "    return tmp\n",
    "\n",
    "def get_input(train):\n",
    "    \n",
    "    len_app = 28\n",
    "    seq_app = 'AGCUAGCUAGCUAGCUAGCUAGCUAGCU'\n",
    "    loop_app = 'SSSSMMMMIIIIBBBBHHHHEEEEXXXX'\n",
    "    stru_app = '.'*len_app\n",
    "    \n",
    "    train = train.copy()\n",
    "    train['sequence'] = train['sequence'].apply(lambda x: x+seq_app)\n",
    "    train['bpRNA_string'] = train['bpRNA_string'].apply(lambda x: x+loop_app)\n",
    "    train['structure'] = train['structure'].apply(lambda x: x+stru_app)\n",
    "    \n",
    "    mapping = {}\n",
    "    vocab = [\"A\", \"G\", \"C\", \"U\", \"s\", \"e\"]\n",
    "    for i, s in enumerate(vocab):\n",
    "        mapping[s] = return_ohe(len(vocab), i)\n",
    "    X_node = np.stack(train[\"sequence\"].apply(lambda x : list(map(lambda y : mapping[y], ['s']+list(x)+['e']))))\n",
    "\n",
    "    mapping = {}\n",
    "    vocab = [\"S\", \"M\", \"I\", \"B\", \"H\", \"E\", \"X\"]\n",
    "    for i, s in enumerate(vocab):\n",
    "        mapping[s] = return_ohe(len(vocab), i)\n",
    "    X_loop = np.stack(train[\"bpRNA_string\"].apply(lambda x : list(map(lambda y : mapping[y], list(x)))))\n",
    "    X_loop = np.concatenate([np.zeros((X_loop.shape[0], 1, X_loop.shape[2])), X_loop, np.zeros((X_loop.shape[0], 1, X_loop.shape[2]))], axis=1)\n",
    "    \n",
    "\n",
    "    mapping = {}\n",
    "    vocab = [\".\", \"(\", \")\"]\n",
    "    for i, s in enumerate(vocab):\n",
    "        mapping[s] = return_ohe(len(vocab), i)\n",
    "    X_structure = np.stack(train[\"structure\"].apply(lambda x : list(map(lambda y : mapping[y], list(x)))))\n",
    "    X_structure = np.concatenate([np.zeros((X_structure.shape[0], 1, X_structure.shape[2])), X_structure, np.zeros((X_structure.shape[0], 1, X_structure.shape[2]))], axis=1)\n",
    "    \n",
    "    \n",
    "    X_node = np.concatenate([X_node, X_loop], axis = 2)\n",
    "    \n",
    "    ## interaction\n",
    "    a = np.sum(X_node * (2 ** np.arange(X_node.shape[2])[None, None, :]), axis = 2)\n",
    "    vocab = sorted(set(a.flatten()))\n",
    "    #print(vocab)\n",
    "    ohes = []\n",
    "    for v in vocab:\n",
    "        ohes.append(a == v)\n",
    "    ohes = np.stack(ohes, axis = 2)\n",
    "    X_node = np.concatenate([X_node, ohes], axis = 2).astype(np.float32)\n",
    "    \n",
    "    X_node = np.concatenate([X_node[:, :(-len_app-1), :], X_node[:, -1, :][:, None,:]], axis=1)\n",
    "    #print(X_node.shape)\n",
    "    return X_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3822, 3822)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy and edited from https://www.kaggle.com/xhlulu/openvaccine-simple-gru-model\n",
    "\n",
    "token2int = {x:i for i, x in enumerate('().ACGUBEHIMSXse')}\n",
    "\n",
    "def pandas_list_to_array(df):\n",
    "    \"\"\"\n",
    "    Input: dataframe of shape (x, y), containing list of length l\n",
    "    Return: np.array of shape (x, l, y)\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.transpose(\n",
    "        np.array(df.values.tolist()),\n",
    "        (0, 2, 1)\n",
    "    )\n",
    "\n",
    "def get_pair_idx(arr, sft=0):\n",
    "    n = len(arr)\n",
    "    out = np.zeros((n))\n",
    "    l = []\n",
    "    for c, i in enumerate(arr):\n",
    "        if i == '.':\n",
    "            out[c] = c\n",
    "        elif i == '(':\n",
    "            l.append(c)\n",
    "        else:\n",
    "            temp = l.pop()\n",
    "            if sft == 0:\n",
    "                out[c] = temp\n",
    "                out[temp] = c\n",
    "            elif sft >= 1:\n",
    "                out[c] = min(temp+sft, n-1)\n",
    "                out[temp] = max(c-sft, 0)\n",
    "            elif sft <= -1:\n",
    "                out[c] = max(temp-sft, 0)\n",
    "                out[temp] = min(c+sft, n-1)\n",
    "    return out\n",
    "\n",
    "def calc_dist_to_pair(struct):\n",
    "    n = len(struct)\n",
    "    out = np.zeros((n))+10000\n",
    "    curr_dist = 10000\n",
    "    for c,i in enumerate(struct):\n",
    "        curr_dist += 1\n",
    "        if i in ['(', ')']:\n",
    "            out[c] = 1\n",
    "            curr_dist = 0\n",
    "        else:\n",
    "            out[c] = min(out[c], curr_dist)\n",
    "    curr_dist = 10000\n",
    "    for c,i in enumerate(struct[::-1]):\n",
    "        curr_dist += 1\n",
    "        if i in ['(', ')']:\n",
    "            out[n-1-c] = 0\n",
    "            curr_dist = 0\n",
    "        else:\n",
    "            out[n-1-c] = min(out[n-1-c], curr_dist)\n",
    "    return out\n",
    "\n",
    "\n",
    "def calc_dist_to_single(struct):\n",
    "    n = len(struct)\n",
    "    out = np.zeros((n))+10000\n",
    "    curr_dist = 10000\n",
    "    for c,i in enumerate(struct):\n",
    "        curr_dist += 1\n",
    "        if i == '.':\n",
    "            out[c] = 1\n",
    "            curr_dist = 0\n",
    "        else:\n",
    "            out[c] = min(out[c], curr_dist)\n",
    "    curr_dist = 10000\n",
    "    for c,i in enumerate(struct[::-1]):\n",
    "        curr_dist += 1\n",
    "        if i == '.':\n",
    "            out[n-1-c] = 0\n",
    "            curr_dist = 0\n",
    "        else:\n",
    "            out[n-1-c] = min(out[n-1-c], curr_dist)\n",
    "    return out\n",
    "\n",
    "\n",
    "def preprocess_inputs1(df, token2int, cols=['sequence', 'structure', 'bpRNA_string']):\n",
    "    return pandas_list_to_array(\n",
    "        df[cols].applymap(lambda seq: [token2int[x] for x in 's'+seq+'e'])\n",
    "    )\n",
    "def preprocess_inputs(df, token2int):\n",
    "    dict_row_idx = {}\n",
    "\n",
    "    train_inputs = preprocess_inputs1(df, token2int)\n",
    "    new = np.zeros((train_inputs.shape[0], train_inputs.shape[1], len(token2int)))\n",
    "    for layer in range(3):\n",
    "        for i in range(len(token2int)):\n",
    "            new[train_inputs[:, :, layer]==i, i]=1\n",
    "\n",
    "    if BBP_TOTAL>=1:\n",
    "        bbp =[]\n",
    "        bbp1 =[]\n",
    "        bbp2 = []\n",
    "        bbp3 = []\n",
    "        bbp4_0 = []\n",
    "        bbp4_1 = []\n",
    "        bbp4_2 = []\n",
    "        bbp4_3 = []\n",
    "\n",
    "        ids = df.id.values\n",
    "        for c, i in enumerate(ids):\n",
    "\n",
    "            probability = bp_matrix\n",
    "            if BBP:\n",
    "                bbp.append(probability.max(-1).tolist())\n",
    "            if BBP1:\n",
    "                bbp1.append((1-probability.sum(axis=1)).tolist())\n",
    "            if BBP2:\n",
    "                srt = np.sort(probability)\n",
    "                bbp2.append((srt[:,-1] - srt[:, -2]).tolist())\n",
    "            if BBP3:\n",
    "                m_lst = probability.max(axis=0)\n",
    "                argmax_lst = m_lst[np.argmax(probability, axis=0)]\n",
    "                bbp3.append((argmax_lst-m_lst).tolist())\n",
    "            if BBP4:\n",
    "                pair_idx = get_pair_idx(df.structure.values[c]).astype(int)\n",
    "                pij = probability[np.arange(len(pair_idx)),pair_idx]\n",
    "                bbp4_0.append(pij.tolist())\n",
    "                m_lst = probability.max(axis=0)\n",
    "                bbp4_1.append((m_lst-pij).tolist())\n",
    "                bbp4_2.append((m_lst[pair_idx]-pij).tolist())\n",
    "                s_lst = probability.sum(axis=0)\n",
    "                bbp4_3.append((s_lst[pair_idx]-pij).tolist())\n",
    "\n",
    "        temp = np.zeros((train_inputs.shape[0], train_inputs.shape[1]))\n",
    "        if BBP:\n",
    "            temp[:, 1:-1] = np.array(bbp)\n",
    "            dict_row_idx['BBP'] = new.shape[2]\n",
    "            new = np.concatenate([new, temp[:, :,None]], axis=2)\n",
    "        if BBP1:\n",
    "            temp[:, 1:-1] = np.array(bbp1)\n",
    "            dict_row_idx['BBP1'] = new.shape[2]\n",
    "            new = np.concatenate([new, temp[:, :,None]], axis=2)\n",
    "        if BBP2:\n",
    "            temp[:, 1:-1] = np.array(bbp2)\n",
    "            dict_row_idx['BBP2'] = new.shape[2]\n",
    "            new = np.concatenate([new, temp[:, :,None]], axis=2)\n",
    "        if BBP3:\n",
    "            temp[:, 1:-1] = np.array(bbp3)\n",
    "            dict_row_idx['BBP3'] = new.shape[2]\n",
    "            new = np.concatenate([new, temp[:, :,None]], axis=2)\n",
    "        if BBP4: \n",
    "            for cnt, b in enumerate([bbp4_0, bbp4_1, bbp4_2, bbp4_3]):\n",
    "                dict_row_idx['BBP4_%s'%cnt] = new.shape[2]\n",
    "                temp[:, 1:-1] = np.array(b)\n",
    "                new = np.concatenate([new, temp[:, :,None]], axis=2)\n",
    "            dict_row_idx['BBP4_ed'] = new.shape[2]\n",
    "\n",
    "            \n",
    "    if DIST_NEW:\n",
    "        lst_dist = []\n",
    "        lst_dist_sqrt = []\n",
    "        ids = df.id.values\n",
    "        for c, i in enumerate(ids):\n",
    "            temp_dist = calc_dist_to_pair(df['structure'].values[c])+1\n",
    "            lst_dist.append((1/temp_dist).tolist())\n",
    "            lst_dist_sqrt.append((np.sqrt(1/temp_dist)).tolist())\n",
    "        temp = np.zeros((train_inputs.shape[0], train_inputs.shape[1]))\n",
    "        temp[:, 1:-1] = np.array(lst_dist)\n",
    "        new = np.concatenate([new, temp[:, :,None]], axis=2)\n",
    "        temp = np.zeros((train_inputs.shape[0], train_inputs.shape[1]))\n",
    "        temp[:, 1:-1] = np.array(lst_dist_sqrt)\n",
    "        new = np.concatenate([new, temp[:, :,None]], axis=2)\n",
    "        \n",
    "    if DIST_NEW2:\n",
    "        lst_dist = []\n",
    "        lst_dist_sqrt = []\n",
    "        ids = df.id.values\n",
    "        for c, i in enumerate(ids):\n",
    "            temp_dist = calc_dist_to_single(df['structure'].values[c])+1\n",
    "            lst_dist.append((1/temp_dist).tolist())\n",
    "            lst_dist_sqrt.append((np.sqrt(1/temp_dist)).tolist())\n",
    "        temp = np.zeros((train_inputs.shape[0], train_inputs.shape[1]))\n",
    "        temp[:, 1:-1] = np.array(lst_dist)\n",
    "        new = np.concatenate([new, temp[:, :,None]], axis=2)\n",
    "        temp = np.zeros((train_inputs.shape[0], train_inputs.shape[1]))\n",
    "        temp[:, 1:-1] = np.array(lst_dist_sqrt)\n",
    "        new = np.concatenate([new, temp[:, :,None]], axis=2)\n",
    "    \n",
    "\n",
    "    return new[:,:,len(token2int):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_structure_adj(train):\n",
    "    Ss = []\n",
    "    for i in (range(len(train))):\n",
    "        seq_length = train[\"seq_length\"].iloc[i]\n",
    "        structure = train[\"structure\"].iloc[i]\n",
    "        sequence = train[\"sequence\"].iloc[i]\n",
    "\n",
    "        cue = []\n",
    "        a_structures = {\n",
    "            (\"A\", \"U\") : np.zeros([seq_length, seq_length]),\n",
    "            (\"C\", \"G\") : np.zeros([seq_length, seq_length]),\n",
    "            (\"U\", \"G\") : np.zeros([seq_length, seq_length]),\n",
    "            (\"U\", \"A\") : np.zeros([seq_length, seq_length]),\n",
    "            (\"G\", \"C\") : np.zeros([seq_length, seq_length]),\n",
    "            (\"G\", \"U\") : np.zeros([seq_length, seq_length]),\n",
    "        }\n",
    "        a_structure = np.zeros([seq_length, seq_length])\n",
    "        for i in range(seq_length):\n",
    "            if structure[i] == \"(\":\n",
    "                cue.append(i)\n",
    "            elif structure[i] == \")\":\n",
    "                start = cue.pop()\n",
    "                a_structures[(sequence[start], sequence[i])][start, i] = 1\n",
    "                a_structures[(sequence[i], sequence[start])][i, start] = 1\n",
    "        \n",
    "        a_strc = np.stack([a for a in a_structures.values()], axis = 2)\n",
    "        a_strc = np.sum(a_strc, axis = 2, keepdims = True)\n",
    "        Ss.append(a_strc)\n",
    "    \n",
    "    Ss = np.array(Ss)\n",
    "    new = np.zeros((Ss.shape[0], Ss.shape[1]+2, Ss.shape[2]+2, Ss.shape[3]))\n",
    "    new[:, 1:-1, 1:-1, :] = Ss\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_matrix(As):\n",
    "    idx = np.arange(As.shape[1])\n",
    "    Ds = []\n",
    "    for i in range(len(idx)):\n",
    "        d = np.abs(idx[i] - idx)\n",
    "        Ds.append(d)\n",
    "\n",
    "    Ds = np.array(Ds) + 1\n",
    "    Ds = 1/Ds\n",
    "    Ds = Ds[None, :,:]\n",
    "    Ds = np.repeat(Ds, len(As), axis = 0)\n",
    "    \n",
    "    Dss = []\n",
    "    for i in [1, 2, 4]:\n",
    "        Dss.append(Ds ** i)\n",
    "    Ds = np.stack(Dss, axis = 3)\n",
    "    return Ds\n",
    "\n",
    "\n",
    "def padding_2D(Ss):\n",
    "    new = np.zeros((Ss.shape[0], Ss.shape[1]+2, Ss.shape[2]+2))\n",
    "    new[:, 1:-1, 1:-1] = Ss\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs(df_temp):\n",
    "    \n",
    "\n",
    "    X_node = get_input(df_temp).astype(np.float32)\n",
    "    X_node_new = preprocess_inputs(df_temp, token2int).astype(np.float32)\n",
    "    X_node = np.concatenate([X_node, X_node_new], axis=2)\n",
    "    del X_node_new\n",
    "\n",
    "\n",
    "    As = [bp_matrix]\n",
    "    \n",
    "    As = np.array(As)\n",
    "    As = padding_2D(As)\n",
    "    Ss = get_structure_adj(df_temp).astype(np.float32)\n",
    "    Ds = get_distance_matrix(As)\n",
    "    DDs = get_distance_matrix_2d(Ss)\n",
    "    As = np.concatenate([As[:,:,:,None],Ss, Ds, DDs], axis = 3).astype(np.float32)\n",
    "    del Ss, Ds, DDs\n",
    "    return X_node, As\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:06<00:00,  6.46s/it]\n"
     ]
    }
   ],
   "source": [
    "dict_X = {}\n",
    "dict_A = {}\n",
    "for i in tqdm(df.id.values):\n",
    "    df_temp = df.loc[df.id == i]\n",
    "    dict_X[i], dict_A[i] = get_inputs(df_temp)\n",
    "    \n",
    "X_node, As = dict_X[0], dict_A[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:12<00:00, 12.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min, sys: 22.3 s, total: 3min 23s\n",
      "Wall time: 42.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "config = {}\n",
    "Diversity_type = 'lstm'\n",
    "wgts_dir = '../../model_files/ov-v40032-wgts/'\n",
    "base = get_base(config)\n",
    "model = get_model(base, config)\n",
    "for m in range(5):\n",
    "    print(m)\n",
    "    model.load_weights(wgts_dir+'model_%s.h5'%m)\n",
    "    preds_ls = []\n",
    "    for uid in tqdm(df.id.values):\n",
    "        X_node, As = dict_X[uid], dict_A[uid]\n",
    "        out1 = model.predict([X_node, As])\n",
    "        out2 = model.predict([reverse_input(X_node), reverse_BBP_3D(As)])\n",
    "        out = (out1+out2)/2\n",
    "        \n",
    "        single_pred = out[0]\n",
    "        single_df = pd.DataFrame(single_pred, columns=pred_cols)\n",
    "        single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n",
    "        preds_ls.append(single_df)\n",
    "        del out1, out2, out, single_pred, single_df\n",
    "        \n",
    "    preds_df = pd.concat(preds_ls).set_index('id_seqpos')\n",
    "    preds_df.to_csv(\"sub_%s_%s.csv\"%(Diversity_type, m))\n",
    "    \n",
    "    del preds_df, preds_ls\n",
    "    gc.collect()\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "del base, model\n",
    "gc.collect()\n",
    "\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:12<00:00, 12.56s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.85s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.80s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.84s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 1s, sys: 21.3 s, total: 3min 22s\n",
      "Wall time: 41.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "config = {}\n",
    "Diversity_type = 'gru'\n",
    "wgts_dir = '../../model_files/ov-v40131-wgts/'\n",
    "base = get_base(config)\n",
    "model = get_model(base, config)\n",
    "for m in range(5):\n",
    "    model.load_weights(wgts_dir+'model_%s.h5'%m)\n",
    "    preds_ls = []\n",
    "    for uid in tqdm(df.id):\n",
    "        X_node, As = dict_X[uid], dict_A[uid]\n",
    "        out1 = model.predict([X_node, As])\n",
    "        out2 = model.predict([reverse_input(X_node), reverse_BBP_3D(As)])\n",
    "        out = (out1+out2)/2\n",
    "        \n",
    "        single_pred = out[0]\n",
    "        single_df = pd.DataFrame(single_pred, columns=pred_cols)\n",
    "        single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n",
    "        preds_ls.append(single_df)\n",
    "        del out1, out2, out, single_pred, single_df\n",
    "        \n",
    "    preds_df = pd.concat(preds_ls).set_index('id_seqpos')\n",
    "    preds_df.to_csv(\"sub_%s_%s.csv\"%(Diversity_type, m))\n",
    "    \n",
    "    del preds_df, preds_ls\n",
    "    gc.collect()\n",
    "    gc.collect()\n",
    "\n",
    "del base, model\n",
    "gc.collect()\n",
    "\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:11<00:00, 11.20s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.47s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.49s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.44s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 59s, sys: 20.6 s, total: 3min 19s\n",
      "Wall time: 37.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "config = {}\n",
    "Diversity_type = 'forward'\n",
    "wgts_dir = '../../model_files/ov-v40237-wgts/'\n",
    "base = get_base(config)\n",
    "model = get_model(base, config)\n",
    "for m in range(5):\n",
    "    model.load_weights(wgts_dir+'model_%s.h5'%m)\n",
    "    preds_ls = []\n",
    "    for uid in tqdm(df.id):\n",
    "        X_node, As = dict_X[uid], dict_A[uid]\n",
    "        out1 = model.predict([X_node, As])\n",
    "        out2 = model.predict([reverse_input(X_node), reverse_BBP_3D(As)])\n",
    "        out = (out1+out2)/2\n",
    "        \n",
    "        single_pred = out[0]\n",
    "        single_df = pd.DataFrame(single_pred, columns=pred_cols)\n",
    "        single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n",
    "        preds_ls.append(single_df)\n",
    "        del out1, out2, out, single_pred, single_df\n",
    "        \n",
    "    preds_df = pd.concat(preds_ls).set_index('id_seqpos')\n",
    "    preds_df.to_csv(\"sub_%s_%s.csv\"%(Diversity_type, m))\n",
    "    \n",
    "    del preds_df, preds_ls\n",
    "    gc.collect()\n",
    "    gc.collect()\n",
    "\n",
    "del base, model\n",
    "gc.collect()\n",
    "\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:13<00:00, 13.00s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.42s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.45s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.45s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 57s, sys: 21.4 s, total: 3min 19s\n",
      "Wall time: 42.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "449696"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "config = {}\n",
    "Diversity_type = 'wave'\n",
    "wgts_dir = '../../model_files/ov-v40334-wgts/'\n",
    "base = get_base(config)\n",
    "model = get_model(base, config)\n",
    "for m in range(5):\n",
    "    model.load_weights(wgts_dir+'model_%s.h5'%m)\n",
    "    preds_ls = []\n",
    "    for uid in tqdm(df.id):\n",
    "        X_node, As = dict_X[uid], dict_A[uid]\n",
    "        out1 = model.predict([X_node, As])\n",
    "        out2 = model.predict([reverse_input(X_node), reverse_BBP_3D(As)])\n",
    "        out = (out1+out2)/2\n",
    "        \n",
    "        single_pred = out[0]\n",
    "        single_df = pd.DataFrame(single_pred, columns=pred_cols)\n",
    "        single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n",
    "        preds_ls.append(single_df)\n",
    "        del out1, out2, out, single_pred, single_df\n",
    "        \n",
    "    preds_df = pd.concat(preds_ls).set_index('id_seqpos')\n",
    "    preds_df.to_csv(\"sub_%s_%s.csv\"%(Diversity_type, m))\n",
    "    \n",
    "    del preds_df, preds_ls\n",
    "    gc.collect()\n",
    "    gc.collect()\n",
    "    \n",
    "del base, model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sub_forward_0.csv', 'sub_forward_1.csv', 'sub_forward_2.csv', 'sub_forward_3.csv', 'sub_forward_4.csv', 'sub_gru_0.csv', 'sub_gru_1.csv', 'sub_gru_2.csv', 'sub_gru_3.csv', 'sub_gru_4.csv', 'sub_lstm_0.csv', 'sub_lstm_1.csv', 'sub_lstm_2.csv', 'sub_lstm_3.csv', 'sub_lstm_4.csv', 'sub_wave_0.csv', 'sub_wave_1.csv', 'sub_wave_2.csv', 'sub_wave_3.csv', 'sub_wave_4.csv']\n"
     ]
    }
   ],
   "source": [
    "lst_pred = os.listdir()\n",
    "lst_pred = sorted([x for x in lst_pred if x.startswith('sub_')])\n",
    "print(lst_pred)\n",
    "preds_df_agg = pd.read_csv(lst_pred[0], index_col=0)\n",
    "for n in lst_pred[1:]:\n",
    "    pred_temp = pd.read_csv(n, index_col=0)\n",
    "    pred_temp[pred_temp<-0.5] = -0.5\n",
    "    pred_temp[pred_temp>6] = 6\n",
    "    preds_df_agg += pred_temp\n",
    "preds_df_agg = preds_df_agg/len(lst_pred)\n",
    "preds_df_agg = preds_df_agg.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_seqpos</th>\n",
       "      <th>reactivity</th>\n",
       "      <th>deg_Mg_pH10</th>\n",
       "      <th>deg_Mg_50C</th>\n",
       "      <th>deg_pH10</th>\n",
       "      <th>deg_50C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0.780365</td>\n",
       "      <td>1.039307</td>\n",
       "      <td>1.018978</td>\n",
       "      <td>1.263657</td>\n",
       "      <td>0.911624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_1</td>\n",
       "      <td>0.847565</td>\n",
       "      <td>0.928186</td>\n",
       "      <td>1.045560</td>\n",
       "      <td>1.251067</td>\n",
       "      <td>1.037408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_2</td>\n",
       "      <td>1.033520</td>\n",
       "      <td>1.364915</td>\n",
       "      <td>1.454146</td>\n",
       "      <td>1.617453</td>\n",
       "      <td>1.256440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_3</td>\n",
       "      <td>0.733770</td>\n",
       "      <td>0.952430</td>\n",
       "      <td>0.990270</td>\n",
       "      <td>1.135923</td>\n",
       "      <td>0.982513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_4</td>\n",
       "      <td>0.326095</td>\n",
       "      <td>0.661931</td>\n",
       "      <td>0.787420</td>\n",
       "      <td>0.755681</td>\n",
       "      <td>0.734609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3817</th>\n",
       "      <td>0_3817</td>\n",
       "      <td>0.331640</td>\n",
       "      <td>0.649709</td>\n",
       "      <td>0.838263</td>\n",
       "      <td>0.782891</td>\n",
       "      <td>0.777027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3818</th>\n",
       "      <td>0_3818</td>\n",
       "      <td>0.739488</td>\n",
       "      <td>0.984498</td>\n",
       "      <td>1.020091</td>\n",
       "      <td>1.148701</td>\n",
       "      <td>1.037179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3819</th>\n",
       "      <td>0_3819</td>\n",
       "      <td>1.028070</td>\n",
       "      <td>1.409259</td>\n",
       "      <td>1.473253</td>\n",
       "      <td>1.524106</td>\n",
       "      <td>1.274926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3820</th>\n",
       "      <td>0_3820</td>\n",
       "      <td>0.831655</td>\n",
       "      <td>0.947818</td>\n",
       "      <td>1.040813</td>\n",
       "      <td>1.192582</td>\n",
       "      <td>1.011444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3821</th>\n",
       "      <td>0_3821</td>\n",
       "      <td>0.778521</td>\n",
       "      <td>0.838281</td>\n",
       "      <td>0.959673</td>\n",
       "      <td>1.120687</td>\n",
       "      <td>0.890112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3822 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id_seqpos  reactivity  deg_Mg_pH10  deg_Mg_50C  deg_pH10   deg_50C\n",
       "0          0_0    0.780365     1.039307    1.018978  1.263657  0.911624\n",
       "1          0_1    0.847565     0.928186    1.045560  1.251067  1.037408\n",
       "2          0_2    1.033520     1.364915    1.454146  1.617453  1.256440\n",
       "3          0_3    0.733770     0.952430    0.990270  1.135923  0.982513\n",
       "4          0_4    0.326095     0.661931    0.787420  0.755681  0.734609\n",
       "...        ...         ...          ...         ...       ...       ...\n",
       "3817    0_3817    0.331640     0.649709    0.838263  0.782891  0.777027\n",
       "3818    0_3818    0.739488     0.984498    1.020091  1.148701  1.037179\n",
       "3819    0_3819    1.028070     1.409259    1.473253  1.524106  1.274926\n",
       "3820    0_3820    0.831655     0.947818    1.040813  1.192582  1.011444\n",
       "3821    0_3821    0.778521     0.838281    0.959673  1.120687  0.890112\n",
       "\n",
       "[3822 rows x 6 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
