{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/tunguz/arnie')\n",
    "sys.path.append('/home/tunguz')\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_context('poster')\n",
    "sns.set_style('white')\n",
    "import numpy as np\n",
    "import re\n",
    "from arnie.pfunc import pfunc\n",
    "from arnie.free_energy import free_energy\n",
    "from arnie.bpps import bpps\n",
    "from arnie.mfe import mfe\n",
    "import arnie.utils as utils\n",
    "from decimal import Decimal\n",
    "import ipynb\n",
    "import json\n",
    "import pickle\n",
    "import csv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split,KFold, GroupKFold,StratifiedKFold\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "import pandas as pd\n",
    "\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_structure_to_bps(secstruct):\n",
    "\n",
    "    bps = []\n",
    "\n",
    "    left_delimiters = ['(','{','[']\n",
    "    right_delimiters = [')','}',']']\n",
    "\n",
    "    for (left_delim, right_delim) in list(zip(left_delimiters, right_delimiters)):\n",
    "\n",
    "        left_list = []\n",
    "        for i, char in enumerate(secstruct):\n",
    "            if char == left_delim:\n",
    "                left_list.append(i)\n",
    "\n",
    "            elif char == right_delim:\n",
    "                bps.append([left_list[-1],i])\n",
    "                left_list = left_list[:-1]\n",
    "\n",
    "        assert len(left_list)==0\n",
    "\n",
    "    return bps\n",
    "\n",
    "def secstruct_to_partner(secstruct):\n",
    "    '''Convert secondary structure string to partner array.\n",
    "    I.E. ((.)) -> [4,3,-1,1,0]\n",
    "    '''\n",
    "    bps = convert_structure_to_bps(secstruct)\n",
    "    partner_vec = -1*np.ones([len(secstruct)]) \n",
    "\n",
    "    for (i,j) in bps:\n",
    "        partner_vec[i] = j\n",
    "        partner_vec[j] = i\n",
    "\n",
    "    return partner_vec\n",
    "\n",
    "def write_bprna_string(dbn_string):\n",
    "    '''Input: dot-parenthesis string\n",
    "    Output: bpRNA-style loop type assignments'''\n",
    "    \n",
    "    pair_partners = secstruct_to_partner(dbn_string)\n",
    "    \n",
    "    #print(pair_partners)\n",
    "    bprna_string=['u']*len(dbn_string)\n",
    "\n",
    "    # assign stems\n",
    "    for s_ind, s in enumerate(dbn_string):\n",
    "        if s != '.':\n",
    "            bprna_string[s_ind] = 'S'\n",
    "                \n",
    "    # get loop regions\n",
    "    \n",
    "    while 'u' in ''.join(bprna_string):\n",
    "        #print(''.join(bprna_string))\n",
    "\n",
    "        obj = re.search(r\"uu*\", ''.join(bprna_string))\n",
    "        start_ind, end_ind = obj.start(), obj.end()\n",
    "        \n",
    "        n_open_hps = dbn_string[:start_ind].count(')') - dbn_string[:start_ind].count('(')\n",
    "        \n",
    "        if n_open_hps == 0:\n",
    "            bprna_string[start_ind:end_ind] = 'E'*(end_ind-start_ind)\n",
    "\n",
    "        else:\n",
    "\n",
    "            last_stem_pairing = int(pair_partners[start_ind - 1])\n",
    "            next_stem_pairing = int(pair_partners[end_ind ])\n",
    "            \n",
    "            if last_stem_pairing == end_ind:\n",
    "                bprna_string[start_ind:end_ind] = 'H'*(end_ind-start_ind)\n",
    "\n",
    "            elif (last_stem_pairing - 1 == next_stem_pairing):\n",
    "                bprna_string[start_ind:end_ind] = 'B'*(end_ind-start_ind)\n",
    "                \n",
    "            elif dbn_string[start_ind-1]==')' and dbn_string[end_ind]=='(':\n",
    "                bprna_string[start_ind:end_ind] = 'M'*(end_ind-start_ind)\n",
    "                \n",
    "            else:\n",
    "                if dbn_string[next_stem_pairing+1:last_stem_pairing] == '.'*(last_stem_pairing - next_stem_pairing-1):\n",
    "                    bprna_string[start_ind:end_ind] = 'I'*(end_ind-start_ind)\n",
    "                    bprna_string[next_stem_pairing+1:last_stem_pairing] = 'I'*(last_stem_pairing - next_stem_pairing-1)\n",
    "\n",
    "                else:\n",
    "                    bprna_string[start_ind:end_ind] = 'M'*(end_ind - start_ind)\n",
    "    return ''.join(bprna_string)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_input(sequence, bprna_string, window_size=1, pad=0):\n",
    "    '''Creat input/output for regression model for predicting structure probing data.\n",
    "    Inputs:\n",
    "    \n",
    "    dataframe (in EternaBench RDAT format)\n",
    "    window_size: size of window (in one direction). so window_size=1 is a total window size of 3\n",
    "    pad: number of nucleotides at start to not include\n",
    "    seq (bool): include sequence encoding\n",
    "    struct (bool): include bpRNA structure encoding\n",
    "    \n",
    "    Outputs:\n",
    "    Input array (n_samples x n_features): array of windowed input features\n",
    "    feature_names (list, length = kernel x window): feature names, i.e. `S_-12`\n",
    "    \n",
    "    '''    \n",
    "    inpts = []\n",
    "\n",
    "    feature_kernel=['A','U','G','C','H','E','I','M','B','S', 'X']\n",
    "\n",
    "    length = len(sequence)\n",
    "    arr = np.zeros([length,len(feature_kernel)])\n",
    "        \n",
    "    for index in range(length):\n",
    "        ctr=0\n",
    "        for char in ['A','U','G','C']:\n",
    "            if sequence[index]==char:\n",
    "                arr[index,ctr]+=1\n",
    "            ctr+=1\n",
    "\n",
    "        for char in ['H','E','I','M','B','S', 'X']:\n",
    "            if bprna_string[index]==char:\n",
    "                arr[index,ctr]+=1\n",
    "            ctr+=1\n",
    "\n",
    "        # add zero padding to the side\n",
    "\n",
    "    padded_arr = np.vstack([np.zeros([window_size,len(feature_kernel)]), arr, np.zeros([window_size,len(feature_kernel)])])\n",
    "\n",
    "    for index in range(length):\n",
    "        new_index = index+window_size-pad\n",
    "        tmp = padded_arr[new_index-window_size:new_index+window_size+1]\n",
    "        inpts.append(tmp.flatten())\n",
    "            \n",
    "    return np.array(inpts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS_WGTS = [0.3, 0.3, 0.3, 0.05, 0.05] #column weights, need to sum up to 1\n",
    "\n",
    "\n",
    "DIST_NEW = True\n",
    "DIST_NEW2 = True\n",
    "\n",
    "BBP = True\n",
    "BBP1 = True\n",
    "BBP2 = True\n",
    "BBP3 = True\n",
    "BBP4 = True\n",
    "\n",
    "BBP_TOTAL = BBP+BBP1+BBP2+BBP3+BBP4*4\n",
    "\n",
    "# This will tell us the columns we are predicting\n",
    "pred_cols = ['reactivity', 'deg_Mg_pH10', 'deg_Mg_50C', 'deg_pH10', 'deg_50C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = \"CGCUGUCUGUACUUGUAUCAGUACACUGACGAGUCCCUAAAGGACGAAACAGCG\"\n",
    "mfe_structure = mfe(sequence, package='eternafold')\n",
    "bprna_string = write_bprna_string(mfe_structure)\n",
    "bp_matrix = bpps(sequence, package='eternafold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>bpRNA_string</th>\n",
       "      <th>structure</th>\n",
       "      <th>seq_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>CGCUGUCUGUACUUGUAUCAGUACACUGACGAGUCCCUAAAGGACG...</td>\n",
       "      <td>SSSSSSSSSSSSSHHHHHHSSSSSSBBSMMMMSSSSHHHHHSSSSM...</td>\n",
       "      <td>(((((((((((((......))))))..)....((((.....))))....</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           sequence  \\\n",
       "0   0  CGCUGUCUGUACUUGUAUCAGUACACUGACGAGUCCCUAAAGGACG...   \n",
       "\n",
       "                                        bpRNA_string  \\\n",
       "0  SSSSSSSSSSSSSHHHHHHSSSSSSBBSMMMMSSSSHHHHHSSSSM...   \n",
       "\n",
       "                                           structure  seq_length  \n",
       "0  (((((((((((((......))))))..)....((((.....))))....          54  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data = [{'id': 0, 'sequence': sequence, 'bpRNA_string': bprna_string, 'structure': mfe_structure, 'seq_length': len(sequence)}])\n",
    "df.sort_values(by='seq_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_list_to_array(df):\n",
    "    \"\"\"\n",
    "    Input: dataframe of shape (x, y), containing list of length l\n",
    "    Return: np.array of shape (x, l, y)\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.transpose(\n",
    "        np.array(df.values.tolist()),\n",
    "        (0, 2, 1)\n",
    "    )\n",
    "\n",
    "\n",
    "def calc_neighbor(d, dim, n):\n",
    "    lst_x,lst_y = np.where(d==n)\n",
    "    for c, x in enumerate(lst_x):\n",
    "        y = lst_y[c]    \n",
    "        if x+1<dim:\n",
    "            d[x+1,y] = min(d[x+1,y], n+1)\n",
    "        if y+1<dim:\n",
    "            d[x,y+1] = min(d[x,y+1], n+1)\n",
    "        if x-1>=0:\n",
    "            d[x-1,y] = min(d[x-1,y], n+1)\n",
    "        if y-1>=0:\n",
    "            d[x,y-1] = min(d[x,y-1], n+1)\n",
    "    return d\n",
    "            \n",
    "\n",
    "def get_distance_matrix_2d(Ss):\n",
    "    Ds = []\n",
    "    n = Ss.shape[0]\n",
    "    dim = Ss.shape[1]\n",
    "    for i in range(n):\n",
    "        s = Ss[i,:,:,0]\n",
    "        d = 10+np.zeros_like(s)\n",
    "        d[s==1] = 1\n",
    "        for i in range(dim):\n",
    "            d[i,i] = 0\n",
    "        for x in range(0, 9):\n",
    "            d = calc_neighbor(d, dim, x)\n",
    "        Ds.append(d)\n",
    "    Ds =  np.array(Ds) + 1\n",
    "    Ds = 1/Ds\n",
    "    Ds = Ds[:, :,:, None]\n",
    "    \n",
    "    Dss = []\n",
    "    for i in [1, 2, 4]:\n",
    "        Dss.append(Ds ** i)\n",
    "    Ds = np.stack(Dss, axis = 3)\n",
    "    return Ds[:,:,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss functions\n",
    "def MCRMSE(y_true, y_pred):\n",
    "    colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=(1))\n",
    "    return tf.reduce_mean(tf.sqrt(colwise_mse), axis=1)\n",
    "\n",
    "\n",
    "from tensorflow.keras import losses\n",
    "\n",
    "class MSE(losses.MeanSquaredError):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        losses.MeanSquaredError.__init__(self, *args, **kwargs)\n",
    "\n",
    "    def __call__(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.where(tf.math.is_nan(y_true), y_pred, y_true)\n",
    "        \n",
    "        temp = losses.MeanSquaredError.__call__(self, y_true[:, :, 0], y_pred[:, :, 0], sample_weight=None)\n",
    "        temp = tf.sqrt(temp+1e-12)\n",
    "        temp = tf.tensordot(temp,sample_weight,1)/tf.reduce_sum(sample_weight)\n",
    "        s = temp*LOSS_WGTS[0]\n",
    "#         s = tf.sqrt(temp)*LOSS_WGTS[0]\n",
    "        for i in range(1,5):\n",
    "            temp = losses.MeanSquaredError.__call__(self, y_true[:, :, i], y_pred[:, :, i], sample_weight=None)\n",
    "            temp = tf.sqrt(temp+1e-12)\n",
    "            temp = tf.tensordot(temp,sample_weight,1)/tf.reduce_sum(sample_weight)\n",
    "#             s += tf.sqrt(temp)*LOSS_WGTS[i]\n",
    "            s += (temp)*LOSS_WGTS[i]\n",
    "            \n",
    "        return s\n",
    "    \n",
    "    \n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def mean_squared_error1(y_true, y_pred, sample_weight):\n",
    "    return np.sum((np.sqrt(np.mean((y_true-y_pred)**2, axis=1)))*sample_weight)/np.sum(sample_weight)\n",
    "\n",
    "def MCRMSE_NAN_sample_wgt(y_true, y_pred, sample_weight=None, loss_cap=None):\n",
    "    if loss_cap is not None:\n",
    "        y_true_adj = np.minimum(np.maximum(y_true, y_pred-loss_cap), y_pred+loss_cap)\n",
    "        return MCRMSE_NAN_sample_wgt(y_true_adj, y_pred, sample_weight=sample_weight, loss_cap=None)\n",
    "    \n",
    "    y_wgt = tf.ones_like(y_true)\n",
    "    y_true = tf.where(tf.math.is_nan(y_true), y_pred, y_true)\n",
    "\n",
    "    s = (mean_squared_error1(y_true[:, :, 0], y_pred[:, :, 0], sample_weight=sample_weight)/(tf.reduce_mean(y_wgt[:,:, 0])))*LOSS_WGTS[0]\n",
    "    for i in range(1,5):\n",
    "        s += (mean_squared_error1(y_true[:, :, i], y_pred[:, :, i], sample_weight=sample_weight)/(tf.reduce_mean(y_wgt[:,:, i])))*LOSS_WGTS[i]\n",
    "    return s\n",
    "\n",
    "def MCRMSE_NAN_sample_wgt_single(y_true, y_pred, sample_weight=None, loss_cap=None):\n",
    "    if loss_cap is not None:\n",
    "        y_true_adj = np.minimum(np.maximum(y_true, y_pred-loss_cap), y_pred+loss_cap)\n",
    "        return MCRMSE_NAN_sample_wgt_single(y_true_adj, y_pred, sample_weight=sample_weight, loss_cap=None)\n",
    "        \n",
    "    y_wgt = tf.ones_like(y_true)\n",
    "    y_true = tf.where(tf.math.is_nan(y_true), y_pred, y_true)\n",
    "\n",
    "    s = (mean_squared_error1(y_true[:, :], y_pred[:, :], sample_weight=sample_weight)/(tf.reduce_mean(y_wgt[:,:])))\n",
    "    return s\n",
    "\n",
    "\n",
    "def MCRMSE_NAN(y_true, y_pred, wgt=LOSS_WGTS, loss_cap=None):\n",
    "    return MCRMSE_NAN_sample_wgt(y_true, y_pred, sample_weight=tf.ones_like(y_true[:,0,0]), loss_cap=loss_cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse inputs\n",
    "def reverse_input(train_input):\n",
    "    reverse = train_input[:, ::-1, :]\n",
    "    return reverse\n",
    "\n",
    "def reverse_BBP_3D(mat):\n",
    "    return mat[:, ::-1, ::-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://www.kaggle.com/xhlulu/openvaccine-simple-gru-model\n",
    "\n",
    "def gru_layer(hidden_dim, dropout):\n",
    "    return L.Bidirectional(\n",
    "        L.GRU(hidden_dim, dropout=dropout, return_sequences=True, kernel_initializer='orthogonal')\n",
    "    )\n",
    "\n",
    "\n",
    "def lstm_layer(hidden_dim, dropout):\n",
    "    return L.Bidirectional(\n",
    "              L.LSTM(hidden_dim,dropout=dropout, return_sequences=True,kernel_initializer = 'orthogonal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://www.kaggle.com/ragnar123/wavenet-gru-baseline\n",
    "\n",
    "def wave_block(x, filters, kernel_size, n):\n",
    "    dilation_rates = [2 ** i for i in range(n)]\n",
    "    x = tf.keras.layers.Conv1D(filters = filters, \n",
    "                               kernel_size = 1,\n",
    "                               padding = 'same')(x)\n",
    "    res_x = x\n",
    "    for dilation_rate in dilation_rates:\n",
    "        tanh_out = tf.keras.layers.Conv1D(filters = filters,\n",
    "                          kernel_size = kernel_size,\n",
    "                          padding = 'same', \n",
    "                          activation = 'tanh', \n",
    "                          dilation_rate = dilation_rate)(x)\n",
    "        sigm_out = tf.keras.layers.Conv1D(filters = filters,\n",
    "                          kernel_size = kernel_size,\n",
    "                          padding = 'same',\n",
    "                          activation = 'sigmoid', \n",
    "                          dilation_rate = dilation_rate)(x)\n",
    "        x = tf.keras.layers.Multiply()([tanh_out, sigm_out])\n",
    "        x = tf.keras.layers.Conv1D(filters = filters,\n",
    "                   kernel_size = 1,\n",
    "                   padding = 'same')(x)\n",
    "        res_x = tf.keras.layers.Add()([res_x, x])\n",
    "    return res_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main model edited from https://www.kaggle.com/mrkmakr/covid-ae-pretrain-gnn-attn-cnn\n",
    "\n",
    "def attention(x_inner, x_outer, n_factor, dropout):\n",
    "    x_Q =  L.Conv1D(n_factor, 1, activation='linear', \n",
    "                  kernel_initializer='glorot_uniform',\n",
    "                  bias_initializer='glorot_uniform',\n",
    "                 )(x_inner)\n",
    "    x_K =  L.Conv1D(n_factor, 1, activation='linear', \n",
    "                  kernel_initializer='glorot_uniform',\n",
    "                  bias_initializer='glorot_uniform',\n",
    "                 )(x_outer)\n",
    "    x_V =  L.Conv1D(n_factor, 1, activation='linear', \n",
    "                  kernel_initializer='glorot_uniform',\n",
    "                  bias_initializer='glorot_uniform',\n",
    "                 )(x_outer)\n",
    "    x_KT = L.Permute((2, 1))(x_K)\n",
    "    res = L.Lambda(lambda c: K.batch_dot(c[0], c[1]) / np.sqrt(n_factor))([x_Q, x_KT])\n",
    "    att = L.Lambda(lambda c: K.softmax(c, axis=-1))(res)\n",
    "    att = L.Lambda(lambda c: K.batch_dot(c[0], c[1]))([att, x_V])\n",
    "    return att\n",
    "\n",
    "def multi_head_attention(x, y, n_factor, n_head, dropout):\n",
    "    if n_head == 1:\n",
    "        att = attention(x, y, n_factor, dropout)\n",
    "    else:\n",
    "        n_factor_head = n_factor // n_head\n",
    "        heads = [attention(x, y, n_factor_head, dropout) for i in range(n_head)]\n",
    "        att = L.Concatenate()(heads)\n",
    "        att = L.Dense(n_factor, \n",
    "                      kernel_initializer='glorot_uniform',\n",
    "                      bias_initializer='glorot_uniform',\n",
    "                     )(att)\n",
    "    x = L.Add()([x, att])\n",
    "    x = L.LayerNormalization()(x)\n",
    "    if dropout > 0:\n",
    "        x = L.Dropout(dropout)(x)\n",
    "    return x\n",
    "\n",
    "def res(x, unit, kernel = 3, rate = 0.1):\n",
    "    h = L.Conv1D(unit, kernel, 1, padding = \"same\", activation = None)(x)\n",
    "    h = L.LayerNormalization()(h)\n",
    "    h = L.LeakyReLU()(h)\n",
    "    h = L.Dropout(rate)(h)\n",
    "    return L.Add()([x, h])\n",
    "\n",
    "def forward(x, unit, kernel = 3, rate = 0.1):\n",
    "    h = L.Conv1D(unit, kernel, 1, padding = \"same\", activation = None)(x)\n",
    "    h = L.LayerNormalization()(h)\n",
    "    h = L.Dropout(rate)(h)\n",
    "    h = L.LeakyReLU()(h)\n",
    "    h = res(h, unit, kernel, rate)\n",
    "    return h\n",
    "\n",
    "def adj_attn(x, adj, unit, n = 2, rate = 0.1):\n",
    "    x_a = x\n",
    "    x_as = []\n",
    "    for i in range(n):\n",
    "        x_a = forward(x_a, unit)\n",
    "        x_a = tf.matmul(adj, x_a)\n",
    "        x_as.append(x_a)\n",
    "    if n == 1:\n",
    "        x_a = x_as[0]\n",
    "    else:\n",
    "        x_a = L.Concatenate()(x_as)\n",
    "    x_a = forward(x_a, unit)\n",
    "    return x_a\n",
    "\n",
    "\n",
    "def get_base(config, dim=None):\n",
    "    node = tf.keras.Input(shape = (dim, X_node.shape[2]), name = \"node\")\n",
    "    adj = tf.keras.Input(shape = (dim, dim, As.shape[3]), name = \"adj\")\n",
    "    \n",
    "    adj_learned = L.Dense(1, \"relu\")(adj)\n",
    "    adj_all = L.Concatenate(axis = 3)([adj, adj_learned])\n",
    "        \n",
    "    xs = []\n",
    "    xs.append(node)\n",
    "    x1 = forward(node, 128*2, kernel = 3, rate = 0.1)\n",
    "    x2 = forward(x1, 64*2, kernel = 6, rate = 0.1)\n",
    "    x3 = forward(x2, 32*2, kernel = 15, rate = 0.1)\n",
    "    x4 = forward(x3, 16*2, kernel = 30, rate = 0.1)\n",
    "    x = L.Concatenate()([x1, x2, x3, x4])\n",
    "    \n",
    "    for unit in [64*2, 32*2]:\n",
    "        x_as = []\n",
    "        for i in range(adj_all.shape[3]):\n",
    "            x_a = adj_attn(x, adj_all[:, :, :, i], unit, rate = 0)\n",
    "            x_as.append(x_a)\n",
    "        x_c = forward(x, unit, kernel = 30)\n",
    "        \n",
    "        x = L.Concatenate()(x_as + [x_c])\n",
    "        x = forward(x, unit)\n",
    "        x = multi_head_attention(x, x, unit, 4, 0.0)\n",
    "        xs.append(x)\n",
    "        \n",
    "    x = L.Concatenate()(xs)\n",
    "\n",
    "    model = tf.keras.Model(inputs = [node, adj], outputs = [x])\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_ae_model(base, config, dim=None):\n",
    "    node = tf.keras.Input(shape = (dim, X_node.shape[2]), name = \"node\")\n",
    "    adj = tf.keras.Input(shape = (dim, dim, As.shape[3]), name = \"adj\")\n",
    "\n",
    "    x = base([L.SpatialDropout1D(0.3)(node), adj])\n",
    "    x = forward(x, 64*2, rate = 0.2)\n",
    "    p = L.Dense(X_node.shape[2], \"sigmoid\")(x)\n",
    "    \n",
    "\n",
    "    node_1 = tf.where((node>1-1e-8), node, tf.zeros_like(node))\n",
    "    node_0 = tf.where((node<1e-8), node, tf.ones_like(node))\n",
    "    node_float = tf.where((node<=1-1e-8)&(node>=1e-8), node, p) \n",
    "    \n",
    "    loss = - tf.reduce_mean(20 * node_1 * tf.math.log(p + 1e-4) + (1 - node_0) * tf.math.log(1 - p + 1e-4) - 5*(node_float-p)**2)\n",
    "    \n",
    "    model = tf.keras.Model(inputs = [node, adj], outputs = [loss])\n",
    "    \n",
    "    opt = get_optimizer()\n",
    "    model.compile(optimizer = opt, loss = lambda t, y : y)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_model(base, config, dim=None):\n",
    "    node = tf.keras.Input(shape = (dim, X_node.shape[2]), name = \"node\")\n",
    "    adj = tf.keras.Input(shape = (dim, dim, As.shape[3]), name = \"adj\")\n",
    "    \n",
    "    x = base([node, adj])\n",
    "    if not Diversity_type in ['forward']:\n",
    "        x = forward(x, 128*2, rate = 0.2)\n",
    "    \n",
    "    if Diversity_type == 'gru':\n",
    "        x = gru_layer(128*2, dropout=0.2)(x)\n",
    "    elif Diversity_type == 'lstm':\n",
    "        x = lstm_layer(128*2, dropout=0.2)(x)\n",
    "    elif Diversity_type == 'forward':\n",
    "        x = forward(x, 128*4, kernel=5, rate = 0.1)\n",
    "        x = forward(x, 128*4, kernel=3, rate = 0.1)\n",
    "        x = forward(x, 128*4, kernel=1, rate = 0.1)\n",
    "    elif Diversity_type == 'wave':\n",
    "        dropout = 0.1\n",
    "        x = wave_block(x, 16*2, 3, 12)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Dropout(dropout)(x)\n",
    "\n",
    "        x = wave_block(x, 32*2, 3, 8)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Dropout(dropout)(x)\n",
    "\n",
    "        x = wave_block(x, 64*2, 3, 4)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Dropout(dropout)(x)\n",
    "\n",
    "        x = wave_block(x, 128*2, 3, 1)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Dropout(dropout)(x)\n",
    "    \n",
    "    \n",
    "    x = x[:, 1:-1,:]\n",
    "    x = L.Dense(5)(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs = [node, adj], outputs = [x])\n",
    "    \n",
    "    opt = get_optimizer()\n",
    "    model.compile(optimizer = opt, loss = MSE(reduction=tf.keras.losses.Reduction.NONE))#mcrmse_loss)\n",
    "    return model\n",
    "\n",
    "def get_optimizer():\n",
    "#     sgd = tf.keras.optimizers.SGD(0.05, momentum = 0.9, nesterov=True)\n",
    "    adam = tf.optimizers.Adam()\n",
    "#     radam = tfa.optimizers.RectifiedAdam()\n",
    "#     lookahead = tfa.optimizers.Lookahead(adam, sync_period=6)\n",
    "#     swa = tfa.optimizers.SWA(adam)\n",
    "    return adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sequence\n",
    "def return_ohe(n, i):\n",
    "    tmp = [0] * n\n",
    "    tmp[i] = 1\n",
    "    return tmp\n",
    "\n",
    "def get_input(train):\n",
    "    \n",
    "    len_app = 28\n",
    "    seq_app = 'AGCUAGCUAGCUAGCUAGCUAGCUAGCU'\n",
    "    loop_app = 'SSSSMMMMIIIIBBBBHHHHEEEEXXXX'\n",
    "    stru_app = '.'*len_app\n",
    "    \n",
    "    train = train.copy()\n",
    "    train['sequence'] = train['sequence'].apply(lambda x: x+seq_app)\n",
    "    train['bpRNA_string'] = train['bpRNA_string'].apply(lambda x: x+loop_app)\n",
    "    train['structure'] = train['structure'].apply(lambda x: x+stru_app)\n",
    "    \n",
    "    mapping = {}\n",
    "    vocab = [\"A\", \"G\", \"C\", \"U\", \"s\", \"e\"]\n",
    "    for i, s in enumerate(vocab):\n",
    "        mapping[s] = return_ohe(len(vocab), i)\n",
    "    X_node = np.stack(train[\"sequence\"].apply(lambda x : list(map(lambda y : mapping[y], ['s']+list(x)+['e']))))\n",
    "\n",
    "    mapping = {}\n",
    "    vocab = [\"S\", \"M\", \"I\", \"B\", \"H\", \"E\", \"X\"]\n",
    "    for i, s in enumerate(vocab):\n",
    "        mapping[s] = return_ohe(len(vocab), i)\n",
    "    X_loop = np.stack(train[\"bpRNA_string\"].apply(lambda x : list(map(lambda y : mapping[y], list(x)))))\n",
    "    X_loop = np.concatenate([np.zeros((X_loop.shape[0], 1, X_loop.shape[2])), X_loop, np.zeros((X_loop.shape[0], 1, X_loop.shape[2]))], axis=1)\n",
    "    \n",
    "\n",
    "    mapping = {}\n",
    "    vocab = [\".\", \"(\", \")\"]\n",
    "    for i, s in enumerate(vocab):\n",
    "        mapping[s] = return_ohe(len(vocab), i)\n",
    "    X_structure = np.stack(train[\"structure\"].apply(lambda x : list(map(lambda y : mapping[y], list(x)))))\n",
    "    X_structure = np.concatenate([np.zeros((X_structure.shape[0], 1, X_structure.shape[2])), X_structure, np.zeros((X_structure.shape[0], 1, X_structure.shape[2]))], axis=1)\n",
    "    \n",
    "    \n",
    "    X_node = np.concatenate([X_node, X_loop], axis = 2)\n",
    "    \n",
    "    ## interaction\n",
    "    a = np.sum(X_node * (2 ** np.arange(X_node.shape[2])[None, None, :]), axis = 2)\n",
    "    vocab = sorted(set(a.flatten()))\n",
    "    #print(vocab)\n",
    "    ohes = []\n",
    "    for v in vocab:\n",
    "        ohes.append(a == v)\n",
    "    ohes = np.stack(ohes, axis = 2)\n",
    "    X_node = np.concatenate([X_node, ohes], axis = 2).astype(np.float32)\n",
    "    \n",
    "    X_node = np.concatenate([X_node[:, :(-len_app-1), :], X_node[:, -1, :][:, None,:]], axis=1)\n",
    "    #print(X_node.shape)\n",
    "    return X_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54, 54)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy and edited from https://www.kaggle.com/xhlulu/openvaccine-simple-gru-model\n",
    "\n",
    "token2int = {x:i for i, x in enumerate('().ACGUBEHIMSXse')}\n",
    "\n",
    "def pandas_list_to_array(df):\n",
    "    \"\"\"\n",
    "    Input: dataframe of shape (x, y), containing list of length l\n",
    "    Return: np.array of shape (x, l, y)\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.transpose(\n",
    "        np.array(df.values.tolist()),\n",
    "        (0, 2, 1)\n",
    "    )\n",
    "\n",
    "def get_pair_idx(arr, sft=0):\n",
    "    n = len(arr)\n",
    "    out = np.zeros((n))\n",
    "    l = []\n",
    "    for c, i in enumerate(arr):\n",
    "        if i == '.':\n",
    "            out[c] = c\n",
    "        elif i == '(':\n",
    "            l.append(c)\n",
    "        else:\n",
    "            temp = l.pop()\n",
    "            if sft == 0:\n",
    "                out[c] = temp\n",
    "                out[temp] = c\n",
    "            elif sft >= 1:\n",
    "                out[c] = min(temp+sft, n-1)\n",
    "                out[temp] = max(c-sft, 0)\n",
    "            elif sft <= -1:\n",
    "                out[c] = max(temp-sft, 0)\n",
    "                out[temp] = min(c+sft, n-1)\n",
    "    return out\n",
    "\n",
    "def calc_dist_to_pair(struct):\n",
    "    n = len(struct)\n",
    "    out = np.zeros((n))+10000\n",
    "    curr_dist = 10000\n",
    "    for c,i in enumerate(struct):\n",
    "        curr_dist += 1\n",
    "        if i in ['(', ')']:\n",
    "            out[c] = 1\n",
    "            curr_dist = 0\n",
    "        else:\n",
    "            out[c] = min(out[c], curr_dist)\n",
    "    curr_dist = 10000\n",
    "    for c,i in enumerate(struct[::-1]):\n",
    "        curr_dist += 1\n",
    "        if i in ['(', ')']:\n",
    "            out[n-1-c] = 0\n",
    "            curr_dist = 0\n",
    "        else:\n",
    "            out[n-1-c] = min(out[n-1-c], curr_dist)\n",
    "    return out\n",
    "\n",
    "\n",
    "def calc_dist_to_single(struct):\n",
    "    n = len(struct)\n",
    "    out = np.zeros((n))+10000\n",
    "    curr_dist = 10000\n",
    "    for c,i in enumerate(struct):\n",
    "        curr_dist += 1\n",
    "        if i == '.':\n",
    "            out[c] = 1\n",
    "            curr_dist = 0\n",
    "        else:\n",
    "            out[c] = min(out[c], curr_dist)\n",
    "    curr_dist = 10000\n",
    "    for c,i in enumerate(struct[::-1]):\n",
    "        curr_dist += 1\n",
    "        if i == '.':\n",
    "            out[n-1-c] = 0\n",
    "            curr_dist = 0\n",
    "        else:\n",
    "            out[n-1-c] = min(out[n-1-c], curr_dist)\n",
    "    return out\n",
    "\n",
    "\n",
    "def preprocess_inputs1(df, token2int, cols=['sequence', 'structure', 'bpRNA_string']):\n",
    "    return pandas_list_to_array(\n",
    "        df[cols].applymap(lambda seq: [token2int[x] for x in 's'+seq+'e'])\n",
    "    )\n",
    "def preprocess_inputs(df, token2int):\n",
    "    dict_row_idx = {}\n",
    "\n",
    "    train_inputs = preprocess_inputs1(df, token2int)\n",
    "    new = np.zeros((train_inputs.shape[0], train_inputs.shape[1], len(token2int)))\n",
    "    for layer in range(3):\n",
    "        for i in range(len(token2int)):\n",
    "            new[train_inputs[:, :, layer]==i, i]=1\n",
    "\n",
    "    if BBP_TOTAL>=1:\n",
    "        bbp =[]\n",
    "        bbp1 =[]\n",
    "        bbp2 = []\n",
    "        bbp3 = []\n",
    "        bbp4_0 = []\n",
    "        bbp4_1 = []\n",
    "        bbp4_2 = []\n",
    "        bbp4_3 = []\n",
    "\n",
    "        ids = df.id.values\n",
    "        for c, i in enumerate(ids):\n",
    "\n",
    "            probability = bp_matrix\n",
    "            if BBP:\n",
    "                bbp.append(probability.max(-1).tolist())\n",
    "            if BBP1:\n",
    "                bbp1.append((1-probability.sum(axis=1)).tolist())\n",
    "            if BBP2:\n",
    "                srt = np.sort(probability)\n",
    "                bbp2.append((srt[:,-1] - srt[:, -2]).tolist())\n",
    "            if BBP3:\n",
    "                m_lst = probability.max(axis=0)\n",
    "                argmax_lst = m_lst[np.argmax(probability, axis=0)]\n",
    "                bbp3.append((argmax_lst-m_lst).tolist())\n",
    "            if BBP4:\n",
    "                pair_idx = get_pair_idx(df.structure.values[c]).astype(int)\n",
    "                pij = probability[np.arange(len(pair_idx)),pair_idx]\n",
    "                bbp4_0.append(pij.tolist())\n",
    "                m_lst = probability.max(axis=0)\n",
    "                bbp4_1.append((m_lst-pij).tolist())\n",
    "                bbp4_2.append((m_lst[pair_idx]-pij).tolist())\n",
    "                s_lst = probability.sum(axis=0)\n",
    "                bbp4_3.append((s_lst[pair_idx]-pij).tolist())\n",
    "\n",
    "        temp = np.zeros((train_inputs.shape[0], train_inputs.shape[1]))\n",
    "        if BBP:\n",
    "            temp[:, 1:-1] = np.array(bbp)\n",
    "            dict_row_idx['BBP'] = new.shape[2]\n",
    "            new = np.concatenate([new, temp[:, :,None]], axis=2)\n",
    "        if BBP1:\n",
    "            temp[:, 1:-1] = np.array(bbp1)\n",
    "            dict_row_idx['BBP1'] = new.shape[2]\n",
    "            new = np.concatenate([new, temp[:, :,None]], axis=2)\n",
    "        if BBP2:\n",
    "            temp[:, 1:-1] = np.array(bbp2)\n",
    "            dict_row_idx['BBP2'] = new.shape[2]\n",
    "            new = np.concatenate([new, temp[:, :,None]], axis=2)\n",
    "        if BBP3:\n",
    "            temp[:, 1:-1] = np.array(bbp3)\n",
    "            dict_row_idx['BBP3'] = new.shape[2]\n",
    "            new = np.concatenate([new, temp[:, :,None]], axis=2)\n",
    "        if BBP4: \n",
    "            for cnt, b in enumerate([bbp4_0, bbp4_1, bbp4_2, bbp4_3]):\n",
    "                dict_row_idx['BBP4_%s'%cnt] = new.shape[2]\n",
    "                temp[:, 1:-1] = np.array(b)\n",
    "                new = np.concatenate([new, temp[:, :,None]], axis=2)\n",
    "            dict_row_idx['BBP4_ed'] = new.shape[2]\n",
    "\n",
    "            \n",
    "    if DIST_NEW:\n",
    "        lst_dist = []\n",
    "        lst_dist_sqrt = []\n",
    "        ids = df.id.values\n",
    "        for c, i in enumerate(ids):\n",
    "            temp_dist = calc_dist_to_pair(df['structure'].values[c])+1\n",
    "            lst_dist.append((1/temp_dist).tolist())\n",
    "            lst_dist_sqrt.append((np.sqrt(1/temp_dist)).tolist())\n",
    "        temp = np.zeros((train_inputs.shape[0], train_inputs.shape[1]))\n",
    "        temp[:, 1:-1] = np.array(lst_dist)\n",
    "        new = np.concatenate([new, temp[:, :,None]], axis=2)\n",
    "        temp = np.zeros((train_inputs.shape[0], train_inputs.shape[1]))\n",
    "        temp[:, 1:-1] = np.array(lst_dist_sqrt)\n",
    "        new = np.concatenate([new, temp[:, :,None]], axis=2)\n",
    "        \n",
    "    if DIST_NEW2:\n",
    "        lst_dist = []\n",
    "        lst_dist_sqrt = []\n",
    "        ids = df.id.values\n",
    "        for c, i in enumerate(ids):\n",
    "            temp_dist = calc_dist_to_single(df['structure'].values[c])+1\n",
    "            lst_dist.append((1/temp_dist).tolist())\n",
    "            lst_dist_sqrt.append((np.sqrt(1/temp_dist)).tolist())\n",
    "        temp = np.zeros((train_inputs.shape[0], train_inputs.shape[1]))\n",
    "        temp[:, 1:-1] = np.array(lst_dist)\n",
    "        new = np.concatenate([new, temp[:, :,None]], axis=2)\n",
    "        temp = np.zeros((train_inputs.shape[0], train_inputs.shape[1]))\n",
    "        temp[:, 1:-1] = np.array(lst_dist_sqrt)\n",
    "        new = np.concatenate([new, temp[:, :,None]], axis=2)\n",
    "    \n",
    "\n",
    "    return new[:,:,len(token2int):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_structure_adj(train):\n",
    "    Ss = []\n",
    "    for i in (range(len(train))):\n",
    "        seq_length = train[\"seq_length\"].iloc[i]\n",
    "        structure = train[\"structure\"].iloc[i]\n",
    "        sequence = train[\"sequence\"].iloc[i]\n",
    "\n",
    "        cue = []\n",
    "        a_structures = {\n",
    "            (\"A\", \"U\") : np.zeros([seq_length, seq_length]),\n",
    "            (\"C\", \"G\") : np.zeros([seq_length, seq_length]),\n",
    "            (\"U\", \"G\") : np.zeros([seq_length, seq_length]),\n",
    "            (\"U\", \"A\") : np.zeros([seq_length, seq_length]),\n",
    "            (\"G\", \"C\") : np.zeros([seq_length, seq_length]),\n",
    "            (\"G\", \"U\") : np.zeros([seq_length, seq_length]),\n",
    "        }\n",
    "        a_structure = np.zeros([seq_length, seq_length])\n",
    "        for i in range(seq_length):\n",
    "            if structure[i] == \"(\":\n",
    "                cue.append(i)\n",
    "            elif structure[i] == \")\":\n",
    "                start = cue.pop()\n",
    "                a_structures[(sequence[start], sequence[i])][start, i] = 1\n",
    "                a_structures[(sequence[i], sequence[start])][i, start] = 1\n",
    "        \n",
    "        a_strc = np.stack([a for a in a_structures.values()], axis = 2)\n",
    "        a_strc = np.sum(a_strc, axis = 2, keepdims = True)\n",
    "        Ss.append(a_strc)\n",
    "    \n",
    "    Ss = np.array(Ss)\n",
    "    new = np.zeros((Ss.shape[0], Ss.shape[1]+2, Ss.shape[2]+2, Ss.shape[3]))\n",
    "    new[:, 1:-1, 1:-1, :] = Ss\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_matrix(As):\n",
    "    idx = np.arange(As.shape[1])\n",
    "    Ds = []\n",
    "    for i in range(len(idx)):\n",
    "        d = np.abs(idx[i] - idx)\n",
    "        Ds.append(d)\n",
    "\n",
    "    Ds = np.array(Ds) + 1\n",
    "    Ds = 1/Ds\n",
    "    Ds = Ds[None, :,:]\n",
    "    Ds = np.repeat(Ds, len(As), axis = 0)\n",
    "    \n",
    "    Dss = []\n",
    "    for i in [1, 2, 4]:\n",
    "        Dss.append(Ds ** i)\n",
    "    Ds = np.stack(Dss, axis = 3)\n",
    "    return Ds\n",
    "\n",
    "\n",
    "def padding_2D(Ss):\n",
    "    new = np.zeros((Ss.shape[0], Ss.shape[1]+2, Ss.shape[2]+2))\n",
    "    new[:, 1:-1, 1:-1] = Ss\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs(df_temp):\n",
    "    \n",
    "\n",
    "    X_node = get_input(df_temp).astype(np.float32)\n",
    "    X_node_new = preprocess_inputs(df_temp, token2int).astype(np.float32)\n",
    "    X_node = np.concatenate([X_node, X_node_new], axis=2)\n",
    "    del X_node_new\n",
    "\n",
    "\n",
    "    As = [bp_matrix]\n",
    "    \n",
    "    As = np.array(As)\n",
    "    As = padding_2D(As)\n",
    "    Ss = get_structure_adj(df_temp).astype(np.float32)\n",
    "    Ds = get_distance_matrix(As)\n",
    "    DDs = get_distance_matrix_2d(Ss)\n",
    "    As = np.concatenate([As[:,:,:,None],Ss, Ds, DDs], axis = 3).astype(np.float32)\n",
    "    del Ss, Ds, DDs\n",
    "    return X_node, As\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 23.21it/s]\n"
     ]
    }
   ],
   "source": [
    "dict_X = {}\n",
    "dict_A = {}\n",
    "for i in tqdm(df.id.values):\n",
    "    df_temp = df.loc[df.id == i]\n",
    "    dict_X[i], dict_A[i] = get_inputs(df_temp)\n",
    "    \n",
    "X_node, As = dict_X[0], dict_A[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:09<00:00, 10.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  6.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  6.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  6.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  6.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.2 s, sys: 954 ms, total: 31.1 s\n",
      "Wall time: 28.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "config = {}\n",
    "Diversity_type = 'lstm'\n",
    "wgts_dir = '../../model_files/ov-v40032-wgts/'\n",
    "base = get_base(config)\n",
    "model = get_model(base, config)\n",
    "for m in range(5):\n",
    "    print(m)\n",
    "    model.load_weights(wgts_dir+'model_%s.h5'%m)\n",
    "    preds_ls = []\n",
    "    for uid in tqdm(df.id.values):\n",
    "        X_node, As = dict_X[uid], dict_A[uid]\n",
    "        out1 = model.predict([X_node, As])\n",
    "        out2 = model.predict([reverse_input(X_node), reverse_BBP_3D(As)])\n",
    "        out = (out1+out2)/2\n",
    "        \n",
    "        single_pred = out[0]\n",
    "        single_df = pd.DataFrame(single_pred, columns=pred_cols)\n",
    "        single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n",
    "        preds_ls.append(single_df)\n",
    "        del out1, out2, out, single_pred, single_df\n",
    "        \n",
    "    preds_df = pd.concat(preds_ls).set_index('id_seqpos')\n",
    "    preds_df.to_csv(\"sub_%s_%s.csv\"%(Diversity_type, m))\n",
    "    \n",
    "    del preds_df, preds_ls\n",
    "    gc.collect()\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "del base, model\n",
    "gc.collect()\n",
    "\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:09<00:00,  9.85s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.65it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.9 s, sys: 544 ms, total: 30.4 s\n",
      "Wall time: 27.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "config = {}\n",
    "Diversity_type = 'gru'\n",
    "wgts_dir = '../../model_files/ov-v40131-wgts/'\n",
    "base = get_base(config)\n",
    "model = get_model(base, config)\n",
    "for m in range(5):\n",
    "    model.load_weights(wgts_dir+'model_%s.h5'%m)\n",
    "    preds_ls = []\n",
    "    for uid in tqdm(df.id):\n",
    "        X_node, As = dict_X[uid], dict_A[uid]\n",
    "        out1 = model.predict([X_node, As])\n",
    "        out2 = model.predict([reverse_input(X_node), reverse_BBP_3D(As)])\n",
    "        out = (out1+out2)/2\n",
    "        \n",
    "        single_pred = out[0]\n",
    "        single_df = pd.DataFrame(single_pred, columns=pred_cols)\n",
    "        single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n",
    "        preds_ls.append(single_df)\n",
    "        del out1, out2, out, single_pred, single_df\n",
    "        \n",
    "    preds_df = pd.concat(preds_ls).set_index('id_seqpos')\n",
    "    preds_df.to_csv(\"sub_%s_%s.csv\"%(Diversity_type, m))\n",
    "    \n",
    "    del preds_df, preds_ls\n",
    "    gc.collect()\n",
    "    gc.collect()\n",
    "\n",
    "del base, model\n",
    "gc.collect()\n",
    "\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:08<00:00,  8.99s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.52it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.52it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.3 s, sys: 802 ms, total: 29.1 s\n",
      "Wall time: 26.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "config = {}\n",
    "Diversity_type = 'forward'\n",
    "wgts_dir = '../../model_files/ov-v40237-wgts/'\n",
    "base = get_base(config)\n",
    "model = get_model(base, config)\n",
    "for m in range(5):\n",
    "    model.load_weights(wgts_dir+'model_%s.h5'%m)\n",
    "    preds_ls = []\n",
    "    for uid in tqdm(df.id):\n",
    "        X_node, As = dict_X[uid], dict_A[uid]\n",
    "        out1 = model.predict([X_node, As])\n",
    "        out2 = model.predict([reverse_input(X_node), reverse_BBP_3D(As)])\n",
    "        out = (out1+out2)/2\n",
    "        \n",
    "        single_pred = out[0]\n",
    "        single_df = pd.DataFrame(single_pred, columns=pred_cols)\n",
    "        single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n",
    "        preds_ls.append(single_df)\n",
    "        del out1, out2, out, single_pred, single_df\n",
    "        \n",
    "    preds_df = pd.concat(preds_ls).set_index('id_seqpos')\n",
    "    preds_df.to_csv(\"sub_%s_%s.csv\"%(Diversity_type, m))\n",
    "    \n",
    "    del preds_df, preds_ls\n",
    "    gc.collect()\n",
    "    gc.collect()\n",
    "\n",
    "del base, model\n",
    "gc.collect()\n",
    "\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:10<00:00, 10.82s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.55it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.7 s, sys: 552 ms, total: 34.3 s\n",
      "Wall time: 31.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "449696"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "config = {}\n",
    "Diversity_type = 'wave'\n",
    "wgts_dir = '../../model_files/ov-v40334-wgts/'\n",
    "base = get_base(config)\n",
    "model = get_model(base, config)\n",
    "for m in range(5):\n",
    "    model.load_weights(wgts_dir+'model_%s.h5'%m)\n",
    "    preds_ls = []\n",
    "    for uid in tqdm(df.id):\n",
    "        X_node, As = dict_X[uid], dict_A[uid]\n",
    "        out1 = model.predict([X_node, As])\n",
    "        out2 = model.predict([reverse_input(X_node), reverse_BBP_3D(As)])\n",
    "        out = (out1+out2)/2\n",
    "        \n",
    "        single_pred = out[0]\n",
    "        single_df = pd.DataFrame(single_pred, columns=pred_cols)\n",
    "        single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n",
    "        preds_ls.append(single_df)\n",
    "        del out1, out2, out, single_pred, single_df\n",
    "        \n",
    "    preds_df = pd.concat(preds_ls).set_index('id_seqpos')\n",
    "    preds_df.to_csv(\"sub_%s_%s.csv\"%(Diversity_type, m))\n",
    "    \n",
    "    del preds_df, preds_ls\n",
    "    gc.collect()\n",
    "    gc.collect()\n",
    "    \n",
    "del base, model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sub_forward_0.csv', 'sub_forward_1.csv', 'sub_forward_2.csv', 'sub_forward_3.csv', 'sub_forward_4.csv', 'sub_gru_0.csv', 'sub_gru_1.csv', 'sub_gru_2.csv', 'sub_gru_3.csv', 'sub_gru_4.csv', 'sub_lstm_0.csv', 'sub_lstm_1.csv', 'sub_lstm_2.csv', 'sub_lstm_3.csv', 'sub_lstm_4.csv', 'sub_wave_0.csv', 'sub_wave_1.csv', 'sub_wave_2.csv', 'sub_wave_3.csv', 'sub_wave_4.csv']\n"
     ]
    }
   ],
   "source": [
    "lst_pred = os.listdir()\n",
    "lst_pred = sorted([x for x in lst_pred if x.startswith('sub_')])\n",
    "print(lst_pred)\n",
    "preds_df_agg = pd.read_csv(lst_pred[0], index_col=0)\n",
    "for n in lst_pred[1:]:\n",
    "    pred_temp = pd.read_csv(n, index_col=0)\n",
    "    pred_temp[pred_temp<-0.5] = -0.5\n",
    "    pred_temp[pred_temp>6] = 6\n",
    "    preds_df_agg += pred_temp\n",
    "preds_df_agg = preds_df_agg/len(lst_pred)\n",
    "preds_df_agg = preds_df_agg.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_seqpos</th>\n",
       "      <th>reactivity</th>\n",
       "      <th>deg_Mg_pH10</th>\n",
       "      <th>deg_Mg_50C</th>\n",
       "      <th>deg_pH10</th>\n",
       "      <th>deg_50C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0.149515</td>\n",
       "      <td>0.325840</td>\n",
       "      <td>0.217058</td>\n",
       "      <td>0.994093</td>\n",
       "      <td>0.342562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_1</td>\n",
       "      <td>0.115881</td>\n",
       "      <td>0.328118</td>\n",
       "      <td>0.232141</td>\n",
       "      <td>0.666086</td>\n",
       "      <td>0.340916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_2</td>\n",
       "      <td>0.088601</td>\n",
       "      <td>0.312135</td>\n",
       "      <td>0.232851</td>\n",
       "      <td>0.438949</td>\n",
       "      <td>0.295237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_3</td>\n",
       "      <td>0.090786</td>\n",
       "      <td>0.247075</td>\n",
       "      <td>0.208920</td>\n",
       "      <td>0.336730</td>\n",
       "      <td>0.305425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_4</td>\n",
       "      <td>0.167912</td>\n",
       "      <td>0.550596</td>\n",
       "      <td>0.426438</td>\n",
       "      <td>0.606134</td>\n",
       "      <td>0.528545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0_5</td>\n",
       "      <td>0.326348</td>\n",
       "      <td>0.500347</td>\n",
       "      <td>0.487788</td>\n",
       "      <td>0.559647</td>\n",
       "      <td>0.523833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0_6</td>\n",
       "      <td>0.583517</td>\n",
       "      <td>0.895267</td>\n",
       "      <td>0.785263</td>\n",
       "      <td>0.980141</td>\n",
       "      <td>0.863397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0_7</td>\n",
       "      <td>0.486069</td>\n",
       "      <td>0.321740</td>\n",
       "      <td>0.318336</td>\n",
       "      <td>0.377334</td>\n",
       "      <td>0.422872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0_8</td>\n",
       "      <td>0.312746</td>\n",
       "      <td>0.571205</td>\n",
       "      <td>0.445930</td>\n",
       "      <td>0.499063</td>\n",
       "      <td>0.490774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0_9</td>\n",
       "      <td>0.085805</td>\n",
       "      <td>0.269357</td>\n",
       "      <td>0.185028</td>\n",
       "      <td>0.235890</td>\n",
       "      <td>0.274425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0_10</td>\n",
       "      <td>0.044131</td>\n",
       "      <td>0.163059</td>\n",
       "      <td>0.107866</td>\n",
       "      <td>0.119395</td>\n",
       "      <td>0.131270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0_11</td>\n",
       "      <td>0.081868</td>\n",
       "      <td>0.363271</td>\n",
       "      <td>0.203751</td>\n",
       "      <td>0.227385</td>\n",
       "      <td>0.296643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0_12</td>\n",
       "      <td>0.312905</td>\n",
       "      <td>0.410989</td>\n",
       "      <td>0.294203</td>\n",
       "      <td>0.261792</td>\n",
       "      <td>0.311164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0_13</td>\n",
       "      <td>0.881752</td>\n",
       "      <td>0.557580</td>\n",
       "      <td>0.484426</td>\n",
       "      <td>0.479522</td>\n",
       "      <td>0.596693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0_14</td>\n",
       "      <td>1.069091</td>\n",
       "      <td>0.807129</td>\n",
       "      <td>0.682578</td>\n",
       "      <td>0.548746</td>\n",
       "      <td>0.654292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0_15</td>\n",
       "      <td>1.107261</td>\n",
       "      <td>1.092261</td>\n",
       "      <td>0.860528</td>\n",
       "      <td>0.747739</td>\n",
       "      <td>0.829942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0_16</td>\n",
       "      <td>1.243738</td>\n",
       "      <td>1.181921</td>\n",
       "      <td>0.925920</td>\n",
       "      <td>0.803813</td>\n",
       "      <td>0.773659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0_17</td>\n",
       "      <td>0.862650</td>\n",
       "      <td>0.868203</td>\n",
       "      <td>0.661926</td>\n",
       "      <td>0.649260</td>\n",
       "      <td>0.598130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0_18</td>\n",
       "      <td>0.308546</td>\n",
       "      <td>0.384960</td>\n",
       "      <td>0.320566</td>\n",
       "      <td>0.325992</td>\n",
       "      <td>0.353327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0_19</td>\n",
       "      <td>0.078202</td>\n",
       "      <td>0.165055</td>\n",
       "      <td>0.096525</td>\n",
       "      <td>0.140544</td>\n",
       "      <td>0.137543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0_20</td>\n",
       "      <td>0.064918</td>\n",
       "      <td>0.327568</td>\n",
       "      <td>0.169349</td>\n",
       "      <td>0.208063</td>\n",
       "      <td>0.186313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0_21</td>\n",
       "      <td>0.090791</td>\n",
       "      <td>0.219138</td>\n",
       "      <td>0.116810</td>\n",
       "      <td>0.164685</td>\n",
       "      <td>0.143725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0_22</td>\n",
       "      <td>0.262339</td>\n",
       "      <td>0.339120</td>\n",
       "      <td>0.264831</td>\n",
       "      <td>0.306888</td>\n",
       "      <td>0.290301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0_23</td>\n",
       "      <td>0.356683</td>\n",
       "      <td>0.513919</td>\n",
       "      <td>0.441114</td>\n",
       "      <td>0.384712</td>\n",
       "      <td>0.403286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0_24</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.351353</td>\n",
       "      <td>0.384110</td>\n",
       "      <td>0.304836</td>\n",
       "      <td>0.347529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0_25</td>\n",
       "      <td>0.414196</td>\n",
       "      <td>0.774961</td>\n",
       "      <td>0.739722</td>\n",
       "      <td>0.638949</td>\n",
       "      <td>0.554689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0_26</td>\n",
       "      <td>0.487263</td>\n",
       "      <td>0.525309</td>\n",
       "      <td>0.463895</td>\n",
       "      <td>0.463387</td>\n",
       "      <td>0.514224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0_27</td>\n",
       "      <td>0.560089</td>\n",
       "      <td>0.527658</td>\n",
       "      <td>0.460462</td>\n",
       "      <td>0.480697</td>\n",
       "      <td>0.546890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0_28</td>\n",
       "      <td>0.378425</td>\n",
       "      <td>0.796703</td>\n",
       "      <td>0.750041</td>\n",
       "      <td>0.668676</td>\n",
       "      <td>0.562276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0_29</td>\n",
       "      <td>0.196948</td>\n",
       "      <td>0.301319</td>\n",
       "      <td>0.308199</td>\n",
       "      <td>0.263760</td>\n",
       "      <td>0.290127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0_30</td>\n",
       "      <td>0.272413</td>\n",
       "      <td>0.518138</td>\n",
       "      <td>0.409990</td>\n",
       "      <td>0.386194</td>\n",
       "      <td>0.382755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0_31</td>\n",
       "      <td>0.254694</td>\n",
       "      <td>0.314373</td>\n",
       "      <td>0.226822</td>\n",
       "      <td>0.278556</td>\n",
       "      <td>0.255371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0_32</td>\n",
       "      <td>0.069545</td>\n",
       "      <td>0.220236</td>\n",
       "      <td>0.106076</td>\n",
       "      <td>0.161695</td>\n",
       "      <td>0.131963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0_33</td>\n",
       "      <td>0.063938</td>\n",
       "      <td>0.311372</td>\n",
       "      <td>0.147250</td>\n",
       "      <td>0.195319</td>\n",
       "      <td>0.166535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0_34</td>\n",
       "      <td>0.080071</td>\n",
       "      <td>0.171287</td>\n",
       "      <td>0.096296</td>\n",
       "      <td>0.131945</td>\n",
       "      <td>0.130068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0_35</td>\n",
       "      <td>0.388413</td>\n",
       "      <td>0.412245</td>\n",
       "      <td>0.340125</td>\n",
       "      <td>0.338526</td>\n",
       "      <td>0.365175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0_36</td>\n",
       "      <td>0.986763</td>\n",
       "      <td>0.794539</td>\n",
       "      <td>0.604079</td>\n",
       "      <td>0.539241</td>\n",
       "      <td>0.524581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0_37</td>\n",
       "      <td>1.238678</td>\n",
       "      <td>1.071318</td>\n",
       "      <td>0.809436</td>\n",
       "      <td>0.705031</td>\n",
       "      <td>0.694899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0_38</td>\n",
       "      <td>1.036568</td>\n",
       "      <td>1.009368</td>\n",
       "      <td>0.832318</td>\n",
       "      <td>0.739036</td>\n",
       "      <td>0.815682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0_39</td>\n",
       "      <td>1.048789</td>\n",
       "      <td>0.846836</td>\n",
       "      <td>0.688691</td>\n",
       "      <td>0.589080</td>\n",
       "      <td>0.670829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0_40</td>\n",
       "      <td>0.840811</td>\n",
       "      <td>0.762190</td>\n",
       "      <td>0.600531</td>\n",
       "      <td>0.618606</td>\n",
       "      <td>0.669768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0_41</td>\n",
       "      <td>0.232114</td>\n",
       "      <td>0.313125</td>\n",
       "      <td>0.204145</td>\n",
       "      <td>0.205937</td>\n",
       "      <td>0.234220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0_42</td>\n",
       "      <td>0.068610</td>\n",
       "      <td>0.344638</td>\n",
       "      <td>0.173169</td>\n",
       "      <td>0.220272</td>\n",
       "      <td>0.247058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0_43</td>\n",
       "      <td>0.039309</td>\n",
       "      <td>0.173088</td>\n",
       "      <td>0.105456</td>\n",
       "      <td>0.124987</td>\n",
       "      <td>0.120588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0_44</td>\n",
       "      <td>0.055096</td>\n",
       "      <td>0.200291</td>\n",
       "      <td>0.133513</td>\n",
       "      <td>0.180581</td>\n",
       "      <td>0.215854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0_45</td>\n",
       "      <td>0.255554</td>\n",
       "      <td>0.528519</td>\n",
       "      <td>0.398971</td>\n",
       "      <td>0.424215</td>\n",
       "      <td>0.449934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0_46</td>\n",
       "      <td>0.591409</td>\n",
       "      <td>0.389773</td>\n",
       "      <td>0.385093</td>\n",
       "      <td>0.411047</td>\n",
       "      <td>0.466848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0_47</td>\n",
       "      <td>0.613919</td>\n",
       "      <td>0.924745</td>\n",
       "      <td>0.813558</td>\n",
       "      <td>0.996654</td>\n",
       "      <td>0.876425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0_48</td>\n",
       "      <td>0.289927</td>\n",
       "      <td>0.449374</td>\n",
       "      <td>0.430470</td>\n",
       "      <td>0.502524</td>\n",
       "      <td>0.453097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0_49</td>\n",
       "      <td>0.132975</td>\n",
       "      <td>0.527559</td>\n",
       "      <td>0.399271</td>\n",
       "      <td>0.563887</td>\n",
       "      <td>0.490075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0_50</td>\n",
       "      <td>0.075707</td>\n",
       "      <td>0.220272</td>\n",
       "      <td>0.183619</td>\n",
       "      <td>0.280321</td>\n",
       "      <td>0.269150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0_51</td>\n",
       "      <td>0.074876</td>\n",
       "      <td>0.294153</td>\n",
       "      <td>0.215856</td>\n",
       "      <td>0.394335</td>\n",
       "      <td>0.262969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0_52</td>\n",
       "      <td>0.103456</td>\n",
       "      <td>0.292305</td>\n",
       "      <td>0.222577</td>\n",
       "      <td>0.568561</td>\n",
       "      <td>0.301370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0_53</td>\n",
       "      <td>0.139628</td>\n",
       "      <td>0.349164</td>\n",
       "      <td>0.258124</td>\n",
       "      <td>0.966365</td>\n",
       "      <td>0.379072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_seqpos  reactivity  deg_Mg_pH10  deg_Mg_50C  deg_pH10   deg_50C\n",
       "0        0_0    0.149515     0.325840    0.217058  0.994093  0.342562\n",
       "1        0_1    0.115881     0.328118    0.232141  0.666086  0.340916\n",
       "2        0_2    0.088601     0.312135    0.232851  0.438949  0.295237\n",
       "3        0_3    0.090786     0.247075    0.208920  0.336730  0.305425\n",
       "4        0_4    0.167912     0.550596    0.426438  0.606134  0.528545\n",
       "5        0_5    0.326348     0.500347    0.487788  0.559647  0.523833\n",
       "6        0_6    0.583517     0.895267    0.785263  0.980141  0.863397\n",
       "7        0_7    0.486069     0.321740    0.318336  0.377334  0.422872\n",
       "8        0_8    0.312746     0.571205    0.445930  0.499063  0.490774\n",
       "9        0_9    0.085805     0.269357    0.185028  0.235890  0.274425\n",
       "10      0_10    0.044131     0.163059    0.107866  0.119395  0.131270\n",
       "11      0_11    0.081868     0.363271    0.203751  0.227385  0.296643\n",
       "12      0_12    0.312905     0.410989    0.294203  0.261792  0.311164\n",
       "13      0_13    0.881752     0.557580    0.484426  0.479522  0.596693\n",
       "14      0_14    1.069091     0.807129    0.682578  0.548746  0.654292\n",
       "15      0_15    1.107261     1.092261    0.860528  0.747739  0.829942\n",
       "16      0_16    1.243738     1.181921    0.925920  0.803813  0.773659\n",
       "17      0_17    0.862650     0.868203    0.661926  0.649260  0.598130\n",
       "18      0_18    0.308546     0.384960    0.320566  0.325992  0.353327\n",
       "19      0_19    0.078202     0.165055    0.096525  0.140544  0.137543\n",
       "20      0_20    0.064918     0.327568    0.169349  0.208063  0.186313\n",
       "21      0_21    0.090791     0.219138    0.116810  0.164685  0.143725\n",
       "22      0_22    0.262339     0.339120    0.264831  0.306888  0.290301\n",
       "23      0_23    0.356683     0.513919    0.441114  0.384712  0.403286\n",
       "24      0_24    0.260374     0.351353    0.384110  0.304836  0.347529\n",
       "25      0_25    0.414196     0.774961    0.739722  0.638949  0.554689\n",
       "26      0_26    0.487263     0.525309    0.463895  0.463387  0.514224\n",
       "27      0_27    0.560089     0.527658    0.460462  0.480697  0.546890\n",
       "28      0_28    0.378425     0.796703    0.750041  0.668676  0.562276\n",
       "29      0_29    0.196948     0.301319    0.308199  0.263760  0.290127\n",
       "30      0_30    0.272413     0.518138    0.409990  0.386194  0.382755\n",
       "31      0_31    0.254694     0.314373    0.226822  0.278556  0.255371\n",
       "32      0_32    0.069545     0.220236    0.106076  0.161695  0.131963\n",
       "33      0_33    0.063938     0.311372    0.147250  0.195319  0.166535\n",
       "34      0_34    0.080071     0.171287    0.096296  0.131945  0.130068\n",
       "35      0_35    0.388413     0.412245    0.340125  0.338526  0.365175\n",
       "36      0_36    0.986763     0.794539    0.604079  0.539241  0.524581\n",
       "37      0_37    1.238678     1.071318    0.809436  0.705031  0.694899\n",
       "38      0_38    1.036568     1.009368    0.832318  0.739036  0.815682\n",
       "39      0_39    1.048789     0.846836    0.688691  0.589080  0.670829\n",
       "40      0_40    0.840811     0.762190    0.600531  0.618606  0.669768\n",
       "41      0_41    0.232114     0.313125    0.204145  0.205937  0.234220\n",
       "42      0_42    0.068610     0.344638    0.173169  0.220272  0.247058\n",
       "43      0_43    0.039309     0.173088    0.105456  0.124987  0.120588\n",
       "44      0_44    0.055096     0.200291    0.133513  0.180581  0.215854\n",
       "45      0_45    0.255554     0.528519    0.398971  0.424215  0.449934\n",
       "46      0_46    0.591409     0.389773    0.385093  0.411047  0.466848\n",
       "47      0_47    0.613919     0.924745    0.813558  0.996654  0.876425\n",
       "48      0_48    0.289927     0.449374    0.430470  0.502524  0.453097\n",
       "49      0_49    0.132975     0.527559    0.399271  0.563887  0.490075\n",
       "50      0_50    0.075707     0.220272    0.183619  0.280321  0.269150\n",
       "51      0_51    0.074876     0.294153    0.215856  0.394335  0.262969\n",
       "52      0_52    0.103456     0.292305    0.222577  0.568561  0.301370\n",
       "53      0_53    0.139628     0.349164    0.258124  0.966365  0.379072"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
